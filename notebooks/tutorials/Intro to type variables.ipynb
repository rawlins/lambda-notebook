{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Polymorphic types for computational linguistic semantics\n",
    "\n",
    "The lambda notebook supports polymorphic types (variables over types) in certain cases.  Specifically, what is implemented is a version of the Hindley-Milner type system\n",
    "\n",
    "Mechanically, you can write type variables using `X`, `Y`, and `Z` followed by any number or number of primes.  So for example, `<X,Y15>` is a function from some type `X` to some type `Y15`.  You also may occasionally see some variable types with the letter `I`; these are internal types and you cannot directly use such types.  See below for ways of dealing with them.\n",
    "\n",
    "In practice, much of formal semantics does not require variable types.  The main use in the lambda notebook is writing general-purpose combinators.  For example, here is a combinator for doing generalized _Predicate Modification_ over arbitrary property types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%lamb\n",
    "gpm = L f_<X,t> : L g_<X,t> : L x_X : f(x) & g(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type variable here signals that the function gpm is underspecified for some type `X`.  All of the `X`s in this formula must be consistent, so whatever `X` is, `g` and `f` must have the same type.  We can see this by combining `gpm` with an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpm(te(\"L x_e : Cat_<e,t>(x)\")).reduce_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpm(te(\"L x_e : Cat_<e,t>(x)\")).reduce_all().derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What has happened here?  The lambda notebook metalanguage inferred at the initial combination stage (reduction is not required) that `X` must be equal to `e`, a non-variable type, and systematically replaced the type variable across all instances in the function.\n",
    "\n",
    "A somewhat more sophisticated example is the implementation of type-checking for function-argument combination in the metalanguage.  The most straightforward algorithm you might imagine would go something like:\n",
    "\n",
    " 1. Is `fun.type` a functional type?  If not, fail.\n",
    " 2. Does `fun.type.left` equal `arg.type`?  If not, fail.\n",
    " 3. Otherwise, succeed.\n",
    " \n",
    "This is a perfectly fine procedure for simple types.  For variable types, we can do something a bit more interesting.\n",
    "\n",
    " 1. Does `fun.type` match `<arg.type,X>`, where `X` is new?  If not, fail.\n",
    " 2. Otherwise, succeed.\n",
    " \n",
    "The procedure for checking if two types match in Hindely-Milner is called _type unification_, and is an instance of first-order unification.  The algorithm for doing type unification is sometimes called _Algorithm U_, after Damas and Milner (1982), _Principal type-schemes for functional programs_, proceedings of ACM POPL.  For example, the type checking for a typical combination of `<e,t>` with `e` boils down to the following call to the type unification procedure (recall that `tp` invokes the type parser), which finds a variable assignment of `X` to `t` that can unify the two types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types.poly_system.unify(tp(\"<e,t>\"), tp(\"<e,X>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to query the variable assignment that unification finds, though most of the time you wouldn't need to do this.  Here is the above example, as well as a somewhat more complicated example of type unification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types.poly_system.unify_details(tp(\"<e,t>\"), tp(\"<e,X>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types.poly_system.unify_details(tp(\"<X,<Y,Z>>\"), tp(\"<Z,<X',e>>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm for doing type inference in the metalanguage is an implementation of Damas and Milner's _Algorithm W_.  This amounts to unifying the constraints imposed by function-argument combination across an entire formula, rather than just a single type.  For example, in the generalized PM example above, we can infer both that `X` maps to `e` and that this is consistent across the formula.  In practice, most cases that are relevant to formal semantics are about this simple.\n",
    "\n",
    "Another example that is useful to consider is the basic function-argument combination of two variable types.  The function's variable gets mapped into a functional type over variables, where the first one matches the argument's variable type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%te f_Z(a_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further inference is of course possible in context, for example, binary truth-functional operators would force `X` in the above result to get mapped to `t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%te f_X(a_Y) & p_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let scoping\n",
    "\n",
    "If you were to run pure type unification from the `types` module on `Z` and `Y` you would get a very different result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types.poly_system.unify_fa(tp(\"Z\"), tp(\"Y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the `I`-prefixed type variable is a new (sometimes termed _fresh_) type variable (the exact number may vary substantially).  For human readability, the output of the `%te` magic reduces the type variables it uses (via a version of alpha conversion) to have low numbers, and not be internal types.  Why is this legitimate?  The result of `%te` as well as assignment in the `%lamb` magic have their type variables in the scope of a `let` operator.  A `let` operator binds type variables and treats them as _generic_.  A variable inside a `let` operator does not have to obey constraints imposed on a variable of the same name not in the scope of that `let`.  Let-scoped expressions may therefore safely have their variables renamed as long as internal type constraints are obeyed.\n",
    "\n",
    "For purposes of formal semantics, one does not typically have to pay much attention to let-scoping or mess with it (in direct contrast to functional programming languages), and so the metalanguage does not indicate it or allow for much manipulation of it.  It is possible to disable let in direct calls to `te`, but currently I don't see that this should be much needed.  Here is the above function-argument example without a let operator, and then with expicit variable renaming performed.  Note that here the input `X` bears no relation to the output `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te(\"f_X(a_Y)\", let=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te(\"f_X(a_Y)\", let=False).compact_type_vars()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In programming languages (/programming language theory) a typical syntax for the let operator is something like:\n",
    "\n",
    "    let f = lambda x: x\n",
    "    in\n",
    "        f(y)\n",
    "    end\n",
    "\n",
    "The type of `x` in this sort of syntax would be treated as generic relative to any type constraints imposed or inferred in the body.  This syntax is implicit in the `%%lamb` magic: any assignment to a variable or lexical item is treated as in the definitional part of a `let` statement, and any use later of that variable/item is treated as having generic type variables.\n",
    "\n",
    "Here is another example, the so-called _Geach combinator_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%lamb\n",
    "geach = L g_<Y,Z> : L f_<X,Y> : L x_X : g(f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a combinator version of function composition, for functions of arbitrary types.  `gc(g)(f)(x)` is equivalent to `(g * f)(x)` where `*` is function composition.  Since the metalanguage allows for `*` to signal function composition, we can see this directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%lamb\n",
    "f = L x_n : x+1\n",
    "g = L x_n : x>3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g * f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geach(g)(f).reduce_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lamb h = L p_t : p & Q_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h * g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geach(h)(g).reduce_all().derivation.trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geach(h)(g).derivation #[0].derivation[0].origin[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geach(h).derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of convenience, there is a special variable notated and entered as `?`.  Simplifying slightly, instances of `?` types do not equal each other (i.e. it is a shorthand for using only fresh type variables).  You can use this when you simply don't know the type, for example, and the `?`s will get translated into regular type variables.  (Note that if you use this without `let`, you may get slightly counterintuitive results unless the type variables are renamed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%te f_?(y_?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lambda Notebook (Python 3)",
   "language": "python",
   "name": "lambda-notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
