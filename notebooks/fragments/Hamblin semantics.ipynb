{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamblin semantics introductory fragment\n",
    "## Author: Kyle Rawlins\n",
    "### Updated: 7/11/16\n",
    "\n",
    "This is an implementation of Hamblin semantics.  It is currently quite incomplete, but walks through the basic principles.  It also may be useful for describing some lexicon manipulation techniques in the lambda notebook (see also the appendix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_lamb()\n",
    "%lambctl reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_e = types.type_e\n",
    "type_t = types.type_t\n",
    "type_n = types.type_n\n",
    "type_s = types.BasicType(\"s\")\n",
    "ts = meta.get_type_system()\n",
    "ts.add_atomic(type_s)\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to 'hamblinize' the lexicon.  This amounts to converting ordinary meanings to singleton sets with their contents.\n",
    "\n",
    "There are a number of options for how to implement this in a typed lambda calculus.  Here, we will exploit the fact that the Lambda Notebook has a type for sets.  If $\\alpha$ is a type, then $\\{\\alpha\\}$ is the type of sets containing elements of type $\\alpha$.\n",
    "\n",
    "The next bit of code defines a special operation `hamblinize` to simplify the process a bit; it can be safely ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamblinize_te(te):\n",
    "    \"\"\"Hamblinize a single lexical item.  Do so by building a singleton set out of it.\"\"\"\n",
    "    if meta.get_type_system().unify(te.type, meta.tp(\"{X}\")): \n",
    "        # assume this item is already hamblinized\n",
    "        return te\n",
    "    elif meta.get_type_system().unify(te.type, meta.tp(\"<{X},Y>\")): \n",
    "        # heuristic: if function whose domain is a set of some sort, assume that this is a Hamblin operator.\n",
    "        # may miss cases.  Better to just run this on content items...\n",
    "        return te\n",
    "    # wrap the content of the lexical item as a singleton set.\n",
    "    return meta.ListedSet([te])    \n",
    "\n",
    "#continuize_lex(cat1.content)\n",
    "lamb.parsing.eq_transforms[\"hamblin\"] = hamblinize_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamblinize_te(te(\"L x: Cat(x)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this in operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%lamb\n",
    "||cat|| =<hamblin> L x_e : L w_s : Cat(w,x)\n",
    "||gray|| =<hamblin> L x_e : L w_s : Gray(w,x)\n",
    "||john|| =<hamblin> John_e\n",
    "x =<hamblin> L y_e : y\n",
    "||test|| = L x_e : Test(x) # don't hamblinize this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to add a way of composing entries *pointwise*.  The following code implements the most general case of Pointwise FA.\n",
    "\n",
    "In the long run, one would want to automatically simplify these expressions; this is easy to do by hand, but it is a hard problem in the general case, so things are left mostly unsimplified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfa_combinator = %te L f_{<X,Y>} : L a_{X} : Set x_Y : Exists f1_<X,Y> : (Exists a1_X : (f1 << f & a1 << a) & x <=> f1(a1))\n",
    "pfa_combinator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = lang.td_system.copy()\n",
    "system.add_binary_rule(pfa_combinator, \"PFA\")\n",
    "lang.set_system(system)\n",
    "system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "john * cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of automatically simplifying things, I'll exploit the fact that sets are represented differently (as a list) if they are finite, so we can special-case PFA for ListedSets, and fall back on the combinator for the general case.\n",
    "\n",
    "Note that some limited reduction does occur with the $\\in$ operator; $x \\in \\{y \\:|\\: \\phi\\}$ gets converted to $(\\lambda y : \\phi)(x)$ and reduced, illustrated in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = te(\"x_e << (Set y_e : Test_<e,t>(y))\")\n",
    "r.reduce_all().derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pfa_listed(fun, arg):\n",
    "    result = list()\n",
    "    for felem in fun.args:\n",
    "        for aelem in arg.args:\n",
    "            result.append(felem(aelem))\n",
    "    return meta.ListedSet(result)\n",
    "\n",
    "def pfa_general(fun, arg):\n",
    "    ts = meta.get_type_system()\n",
    "    general = pfa_combinator(fun)(arg) # do this for type checking\n",
    "    if isinstance(fun, meta.ListedSet) and isinstance(arg, meta.ListedSet):\n",
    "        return pfa_listed(fun, arg)\n",
    "    else:\n",
    "        return general.reduce_all()\n",
    "    \n",
    "system = lang.td_system.copy()\n",
    "system.add_binary_rule_uncurried(pfa_general, \"PFA\")\n",
    "lang.set_system(system)\n",
    "system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "john * cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%lamb\n",
    "## To simplify, let's take there to only be three human-like entities in the universe.\n",
    "||who|| = {John_e, Mary_e, Sue_e}\n",
    "||saw|| =<hamblin> L x_e : L y_e : L w_s : Saw(w,y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cat * who).tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wh-items compose in situ.  Intuitively, this leads to sets that percolate up the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "john * (saw * who)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(john * (saw * who)).tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "who * (saw * john)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis of existentials in a compositional Hamblin semantics (e.g. for Japanese) can be illustrated in this simple example by adding Hamblin 1-place quantificational operators that compose via ordinary FA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%lamb\n",
    "||HExists|| = L p_{<s,t>} : {(Lambda w_s  : Exists q_<s,t> : q(w) & (q << p))}\n",
    "||HForall|| = L p_{<s,t>} : {(Lambda w_s  : Forall q_<s,t> : q(w) >> (q << p))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HExists * (who * (saw * john))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HExists * (john * (saw * who))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(HExists * (john * (saw * who))).tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More generally, the listed versions of this won't do, because we don't want to assume that the relevant sets are finite.  Or in other words, we don't want to define 'who' extensionally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%lamb\n",
    "||who|| = Set x_e : Human(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment the lambda notebook doesn't do much simplification of these expressions, so they will be a bit unwieldy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cat * who).tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "john * (saw * who)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "who * (saw * john)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HExists * (who * (saw * john))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above formulas are somewhat involved, so it is slightly more convenient to simply define a toy example with a finite set of individuals:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix: another technique for Hamblinization\n",
    "\n",
    "Another way of Hamblinizing a lexicon would be to write extra magics for converting whole lexicons at once.  Here's a sketch of how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamblinize_item(item):\n",
    "    \"\"\"Hamblinize a single lexical item.  Do so by building a singleton set out of it.\"\"\"\n",
    "    if meta.ts_compatible(item.type, meta.tp(\"{?}\")): #isinstance(item.type, types.SetType):\n",
    "        # assume this item is already hamblinized\n",
    "        return item\n",
    "    elif meta.ts_compatible(item.type, meta.tp(\"<{?},?>\")): #item.type.functional() and isinstance(item.type.left, types.SetType):\n",
    "        # heuristic: if function whose domain is a set of some sort, assume that this is a Hamblin operator.\n",
    "        # may miss cases.  Better to just run this on content items...\n",
    "        return item\n",
    "    new_i = item.copy()\n",
    "    # wrap the content of the lexical item as a singleton set.\n",
    "    new_i.content = meta.ListedSet([item.content])\n",
    "    return new_i\n",
    "\n",
    "# in the following two magics, variables that are not lexical items are ignored.  To change this, modify the else case above.\n",
    "def h_magic(self, accum):\n",
    "    \"\"\"Hamblinize the accumulated definitions from a single cell, as a post-processing step\"\"\"\n",
    "    new_accum = lamb.magics.process_items(hamblinize_item, accum)[0]\n",
    "    for k in new_accum.keys():\n",
    "        self.env[k] = new_accum[k]\n",
    "    return new_accum\n",
    "\n",
    "def h_magic_env(self):\n",
    "    \"\"\"Hamblinize the entire env\"\"\"\n",
    "    self.env = lamb.magics.process_items(hamblinize_item, self.env)[0] # hamblinize every variable\n",
    "    self.shell.push(self.env) # export the new variables to the interactive shell\n",
    "    return lamb.parsing.latex_output(self.env, self.env)\n",
    "\n",
    "lamb.magics.LambMagics.specials_post[\"hamblinize\"] = h_magic\n",
    "lamb.magics.LambMagics.specials[\"hamblinize_all\"] = h_magic_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%lamb reset,hamblinize\n",
    "||cat|| = L x_e : L w_s : Cat(w,x)\n",
    "||gray|| = L x_e : L w_s : Gray(w,x)\n",
    "||john|| = J_e\n",
    "x = L y_e : y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%lamb\n",
    "||test|| = L x_e : Test(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lambctl hamblinize_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lambda Notebook (Python 3)",
   "language": "python",
   "name": "lambda-notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
