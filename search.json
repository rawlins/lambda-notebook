[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The lambda notebook package: linguistic semantics in Python and Jupyter",
    "section": "",
    "text": "%%lamb\n||a|| = L f_&lt;e,t&gt; : L g_&lt;e,t&gt; : Exists x_e : f(x) &gt;&gt; g(x)\n||cat|| = L x_e : Cat_&lt;e,t&gt;(x)\n||meowed|| = L x_e : Meowed_&lt;e,t&gt;(x)\n\n\\([\\![\\text{\\textbf{a}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} f_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\lambda{} g_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\exists{} x_{e} \\: . \\: {f}({x}) \\rightarrow{} {g}({x})\\) \\([\\![\\text{\\textbf{cat}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {Cat}({x})\\) \\([\\![\\text{\\textbf{meowed}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {Meowed}({x})\\)\n((a * cat) * meowed).tree()\n\n1 composition path:$[\\![\\text{\\textbf{a}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},t\\right\\rangle{}\\right\\rangle{}}$$\\lambda{} f_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\lambda{} g_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\exists{} x_{e} \\: . \\: {f}({x}) \\rightarrow{} {g}({x})$*$[\\![\\text{\\textbf{cat}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x})$[FA]$[\\![\\text{\\textbf{[a cat]}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},t\\right\\rangle{}}$$\\lambda{} g_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\exists{} x_{e} \\: . \\: {Cat}({x}) \\rightarrow{} {g}({x})$*$[\\![\\text{\\textbf{meowed}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Meowed}({x})$[FA]$[\\![\\text{\\textbf{[[a cat] meowed]}}]\\!]^{}_{t}$$\\exists{} x_{e} \\: . \\: {Cat}({x}) \\rightarrow{} {Meowed}({x})$"
  },
  {
    "objectID": "index.html#working-with-the-metalanguage",
    "href": "index.html#working-with-the-metalanguage",
    "title": "The lambda notebook package: linguistic semantics in Python and Jupyter",
    "section": "3.1 Working with the metalanguage",
    "text": "3.1 Working with the metalanguage\nThe lambda notebook metalanguage is flexible, python-esque typed language that is parsed into structured python objects. One way of instantiating metalanguage objects is to use the %te line magic. The following example builds and renders a universally quantified logical expression:\n\n%te Forall x_e : P_&lt;e,t&gt;(x)\n\n\\(\\forall{} x_{e} \\: . \\: {P}({x})\\)\n\n\nThe following example builds and renders a lambda expression containing a quantified expression. In addition, it assigns the value of this expression to the python variable f:\n\nf = %te L x_e : Forall y_e : Q(x,y)\nf\n\nINFO (core): Coerced guessed type for 'Q_t' into &lt;(e,e),t&gt;, to match argument '(x_e, y_e)'\n\n\n\\(\\lambda{} x_{e} \\: . \\: \\forall{} y_{e} \\: . \\: {Q}({x}, {y})\\)\n\n\nf can now be examined and manipulated in various ways, for example by using indexing to inspect its structure, or looking at its type property.\n\nf[1]\n\n\\(\\forall{} y_{e} \\: . \\: {Q}({x}_{e}, {y})\\)\n\n\n\nf.type\n\n\\(\\left\\langle{}e,t\\right\\rangle{}\\)\n\n\nMore info: For more information on the metalanguage and its capabilities, see the various documentation notebooks in the source repository."
  },
  {
    "objectID": "index.html#working-with-composition-systems",
    "href": "index.html#working-with-composition-systems",
    "title": "The lambda notebook package: linguistic semantics in Python and Jupyter",
    "section": "3.2 Working with composition systems",
    "text": "3.2 Working with composition systems\nYou can use metalanguage objects to define lexical entries that can the be composed with a “composition system” – a collection of composition operations. The default composition system is a standard one with Function Application and several other rules familiar from e.g. Heim and Kratzer 1998.\nTo replicate the starting example in this document, we can first define lexical entries for the three words using metalanguage code in the %%lamb cell magic:\n\n%%lamb\n||every|| = L f_&lt;e,t&gt; : L g_&lt;e,t&gt; : Forall x_e : f(x) &gt;&gt; g(x)\n||cat|| = L x_e : Cat_&lt;e,t&gt;(x)\n||meowed|| = L x_e : Meowed_&lt;e,t&gt;(x)\n\n\\([\\![\\text{\\textbf{every}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} f_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\lambda{} g_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\forall{} x_{e} \\: . \\: {f}({x}) \\rightarrow{} {g}({x})\\) \\([\\![\\text{\\textbf{cat}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {Cat}({x})\\) \\([\\![\\text{\\textbf{meowed}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {Meowed}({x})\\)\n\n\nThe rendered outputs will look relatively familiar from an introductory semantics class. Lexical entries defined this way are also exported to the outer namespace in a jupyter context, so we can refer to the entries via their names in python as well. Now that these entries are defined, the python * operator is overloaded to do composition according to the current composition system. For example, to compose “every” and “cat” above, we can simply write:\n\nevery * cat\n\n1 composition path. Result:     [0]: \\([\\![\\text{\\textbf{[every cat]}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},t\\right\\rangle{}} \\:=\\: \\lambda{} g_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\forall{} x_{e} \\: . \\: {Cat}({x}) \\rightarrow{} {g}({x})\\)\n\n\nThere’s quite a lot of manipulation and introspection that can be done with composition objects, but for example, the following shows a step by step breakdown with the rules indicated:\n\n(every * cat).trace()\n\nFull composition trace. 1 path:     Step 1: \\([\\![\\text{\\textbf{every}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} f_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\lambda{} g_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\forall{} x_{e} \\: . \\: {f}({x}) \\rightarrow{} {g}({x})\\)     Step 2: \\([\\![\\text{\\textbf{cat}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {Cat}({x})\\)     Step 3: \\([\\![\\text{\\textbf{every}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},t\\right\\rangle{}\\right\\rangle{}}\\) * \\([\\![\\text{\\textbf{cat}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}\\) leads to: \\([\\![\\text{\\textbf{[every cat]}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},t\\right\\rangle{}} \\:=\\: \\lambda{} g_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\forall{} x_{e} \\: . \\: {Cat}({x}) \\rightarrow{} {g}({x})\\) [by FA]\n\n\nThe following (which adds the main verb as well) shows a more complex sequence with a tree-like visualization:\n\n((every * cat) * meowed).tree()\n\n1 composition path:$[\\![\\text{\\textbf{every}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},t\\right\\rangle{}\\right\\rangle{}}$$\\lambda{} f_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\lambda{} g_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\forall{} x_{e} \\: . \\: {f}({x}) \\rightarrow{} {g}({x})$*$[\\![\\text{\\textbf{cat}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x})$[FA]$[\\![\\text{\\textbf{[every cat]}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},t\\right\\rangle{}}$$\\lambda{} g_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\forall{} x_{e} \\: . \\: {Cat}({x}) \\rightarrow{} {g}({x})$*$[\\![\\text{\\textbf{meowed}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Meowed}({x})$[FA]$[\\![\\text{\\textbf{[[every cat] meowed]}}]\\!]^{}_{t}$$\\forall{} x_{e} \\: . \\: {Cat}({x}) \\rightarrow{} {Meowed}({x})$\n\n\nOf course, Function Application (and other composition rules) will ensure that types are verified, and composition won’t succeed if the types are mismatched. For example, “every” wouldn’t be able to compose directly with a two-place (type \\(\\langle e, \\langle e,t \\rangle \\rangle\\)) predicate:\n\n%%lamb\n||sister|| = L x_e  : L y_e : SisterOf(y,x)\n\nINFO (core): Coerced guessed type for 'SisterOf_t' into &lt;(e,e),t&gt;, to match argument '(y_e, x_e)'\n\n\n\\([\\![\\text{\\textbf{sister}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: \\lambda{} y_{e} \\: . \\: {SisterOf}({y}, {x})\\)\n\n\n\nevery * sister\n\nComposition of “[every sister]” failed:     TypeMismatch: \\([\\![\\text{\\textbf{every}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} f_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\lambda{} g_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\forall{} x_{e} \\: . \\: {f}({x}) \\rightarrow{} {g}({x})\\) and \\([\\![\\text{\\textbf{sister}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: \\lambda{} y_{e} \\: . \\: {SisterOf}({y}, {x})\\) conflict (Function Application needs a matching function and argument)     TypeMismatch: \\([\\![\\text{\\textbf{sister}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: \\lambda{} y_{e} \\: . \\: {SisterOf}({y}, {x})\\) and \\([\\![\\text{\\textbf{every}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} f_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\lambda{} g_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\forall{} x_{e} \\: . \\: {f}({x}) \\rightarrow{} {g}({x})\\) conflict (Function Application needs a matching function and argument)     TypeMismatch: \\([\\![\\text{\\textbf{every}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} f_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\lambda{} g_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\forall{} x_{e} \\: . \\: {f}({x}) \\rightarrow{} {g}({x})\\) and \\([\\![\\text{\\textbf{sister}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: \\lambda{} y_{e} \\: . \\: {SisterOf}({y}, {x})\\) conflict (Predicate Modification needs property types)     Composition failure on: \\([\\![\\text{\\textbf{every}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} f_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\lambda{} g_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\forall{} x_{e} \\: . \\: {f}({x}) \\rightarrow{} {g}({x})\\) * \\([\\![\\text{\\textbf{sister}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: \\lambda{} y_{e} \\: . \\: {SisterOf}({y}, {x})\\) (Predicate Abstraction requires a valid binder)     Composition failure on: \\([\\![\\text{\\textbf{sister}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: \\lambda{} y_{e} \\: . \\: {SisterOf}({y}, {x})\\) * \\([\\![\\text{\\textbf{every}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} f_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\lambda{} g_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\forall{} x_{e} \\: . \\: {f}({x}) \\rightarrow{} {g}({x})\\) (Predicate Abstraction requires a valid binder)     TypeMismatch: \\([\\![\\text{\\textbf{every}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} f_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\lambda{} g_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: \\forall{} x_{e} \\: . \\: {f}({x}) \\rightarrow{} {g}({x})\\) and \\([\\![\\text{\\textbf{sister}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: \\lambda{} y_{e} \\: . \\: {SisterOf}({y}, {x})\\) conflict (Vacuous composition needs at least one fully vacuous element)\n\n\nYou can see from the above that the default composition system has a number of other rules that are tried in addition to standard FA, but of course none of them work in this case.\nMore info: For more on composition systems and composition, see the interactive documentation notebook as well as many example fragments that illustrate how to do things like modify a composition system."
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "Changelog for lambda-notebook",
    "section": "",
    "text": "The next release will be 0.8.0, and involves a major metalanguage/type system update, centered around a new approach to metasemantics. This is probably the biggest set of changes since the initial release.\nNew features:\n\nMeta-meta-language (new module, lamb.meta.meta):\n\nMetaTerm: this is a major change/improvement to how constant values (e.g. True) work. A MetaTerm is a direct, immutable reference to a backing python object that provides a metasemantics for the term. This change goes together with an explicit implementation of domain sets of python objects, providing backing domains for all simple types (e.g. type e is backed by strings of a certain kind, SetType is backed by python sets, functions are backed by mappings/callables, etc).\nSimplification guarantees complete simplification when dealing with MetaTerms. This change also allows simplification for quantified expressions with finite domains (by iterating over the type domain).\nEvaluations: much richer support for truth-table-like batch evaluations of boolean expressions. truthtable is a handy wrapper function on this.\nextract_boolean: given an arbitrary metalanguage expression, produce a purely boolean expression together with an assignment filling in the non-boolean parts.\n\nMetalanguage set operations and relations\n\ncore operations: intersection, union, difference. Core relations: equivalence, the various sub/superset relations.\ncorresponding simplification heuristics.\n\nType system features:\n\nAs noted above, the ontology for simple types is new essentially complete, at least for the finite case, by implementing domain sets.\nType domains allow domain restriction in order to work with finite examples. The easiest api for this is the context manager function restrict_domain on atomic types.\nA new type constructor (∀) that unselectively binds type variables in its scope. This is only semi-intended to be user facing, as it isn’t easy to understand. However, this directly supports the next feature:\nSupport for full let-polymorphism via assignments. That is, polymorphic functions in assignments can now have distinct specializations in the same expression (previously they would have to unify to a coherent type; let-polymorphism could only be achieved anonymously via reduction).\n\nMetalanguage “compilation”: expressions with no free variables can now be converted to python code that runs roughly within an order of magnitude of similar code implemented directly in python. In many cases, this is much faster than simplification, and sometimes in a way that matters (especially with quantification in play). There are certain other caveats: finite sets only, equivalence of functions can’t be dynamically determined.\nSimplification and expression manipulation features:\n\nnew module, lamb.meta.ply, hosts various code (new and old) for generic manipulation and introspection on TypedExpr objects.\nterm order normalization for n-ary operations where this is appropriate (e.g. &, |). This normalizes order and structure (to left commutivity). This approach allows keeping strict binary operators, but when appropriate, manipulating them as n-ary sequences.\nmore configurable simplification, with a number of options that may not be used by default. (Roughly building on SymPy’s approach.) For example, the eliminate_sets option will convert set operations/relations to booleans where possible, though this may make formulas more complicated.\n\nError / exception handling and display, especially in magic contexts, is rewritten. New context manager lamb.errors() allows clean handling of lambda notebook-specific errors.\nComposition:\n\ncompose order is now preserved and used in rendering for bottom-up composition.\ncomposition objects now support a function source_tree(), which extracts an underlying nltk-style Tree for display.\n\n\nDocumentation and sample notebooks:\n\nNew documentation for sets, meta-meta-language expressions\nRewritten: Hamblin semantics fragment\n\nFixes, improvements, changes:\n\ntypes and related issues:\n\nmany internal improvements/changes to type inference. One thing to note is that internal type variables will now appear as ? followed by a number, rather than as I variables.\nimprovements to anonymous let-polymorphism, which was previously very non-general\nMany bug fixes to do with polymorphism\n\nimprovements to simplification with recursive Tuple expressions\nimprovements to inference for Partial expressions.\nimprovements to derivations. The most public-facing change is that derivation reasons are now visually aligned with the origin step, not the result step. These objects now better support introspection, as well.\nmany improvements to metalanguage simplification and reduction heuristics.\nimprovements to latex rendering compatibility, including colab (katex) and mathjax 3.\nOlder support code has been removed\n\n\n\n\nNew features:\n\nsupport rendering in colab\nquicker loading without the kernel (import lamb.auto)\nrefactor metalanguage code: better support for new operators\n\nFixes:\n\nfix several polymorphic type inference issues\nimproved ipython/jupyter rendering\n\n\n\n\nFix a python 3.10 compatibility bug\n\n\n\nFixes, improvements, changes (highlights):\n\ncorrectly pin the right traitlets version\n\n\n\n\nNew features:\n\ncomposition rule for index percolation in tree composition\ncomposition rule for vacuous nodes (with content=None)\n\nFixes, improvements, changes (highlights):\n\nimprove and generalize lang.Binder behavior\nenable svgling for internal tree drawing\nimprovements to the relative clause notebook\n\n\n\n\nThis is the first version that was released on PyPI.\nNew features:\n\nadded an explicit changelog in this version. (Older changes in this document are backfilled from commit messages.)\nexperimental support for derivations shown using svgling trees\nfull support for installation in site-packages, better kernel installation\n\nFixes, improvements, changes (highlights):\n\nimprove derivation rendering\nimprove cross-browser compatibility\nimprove error messaging and handling of composition failures\n\n\n\n\nDocumentation and notebooks:\n\nIntensional scope fragment (primarily based on Keshet’s work)\n\nFixes, improvements, changes (highlights):\n\nTest improvements\nPartiality rework\nCI (via Travis)\nrepr improvements\n\n\n\n\n(Note: in conventional commit terms this should have definitely been a major version bump.)\nNew features:\n\nChange Predicate Abstraction based on Coppock’s version in Semantics Boot Camp (now Coppock and Champollion)\nRecursive simplification for boolean expressions, numbers\nLexical ambiguity in Items\nMetalanguage operator ExistsExact\nInitial implementation of Heim & Kratzer-style presuppositions via partiality\nDisjunctive type constructor, for ad-hoc polymorphism over simple types; and corresponding Disjunction objects in the metalanguage\ntesting infrastructure, random expression generation\n\nDocumentation:\n\nNew introductory demo notebook\nNew fragment: compositional DRT (from Dee Ann Reisinger)\nMetalanguage quick reference\n\nFixes, improvements, changes (highlights):\n\nFixes and improvements to polymorphism, better testing\nImprovements to composition systems, especially tree-based composition\nImprovements to rich reprs\n\n\n\n\nNew feature:\n\nAllow spaces and underscores in Item names\n\nFixes, improvements, changes (highlights):\n\nvarious display fixes\nupdate for nltk 3+\ndocumentation / notebook fixes\nimprovements to packaging\n\n\n\n\n\npackaging improvements and fixes\n\n\n\n\n\nfix a fragment notebook\n\n\n\n\nNew features:\n\nSupport for polymorphic types and inference via type variables\nCorresponding metalanguage updates\n\nFixes, improvements, changes (highlights):\n\nImprovements for IPython 3\n\n\n\n\nNew features:\n\n%te magic\nnew renderers for recursive / tree-like composition displays\n\nFixes, improvements, changes (highlights):\n\nimprovements to rich reprs\nfixes to reduction\n\n\n\n\nThis version was aiming at basic intro to semantics feature completeness:\n\nthe lambda notebook IPython kernel\ntypes for a simply-typed lambda calculus\na matching more-or-less complete metalanguage for simply-typed lambda calculus\ncomposition systems, rich repr rendering, integration with nltk Tree\nvarious demo and fragment notebooks\npackaging (now completely deprecated)\n\n(Version control begins 2014-01-01.)"
  },
  {
    "objectID": "CHANGELOG.html#unreleased",
    "href": "CHANGELOG.html#unreleased",
    "title": "Changelog for lambda-notebook",
    "section": "",
    "text": "The next release will be 0.8.0, and involves a major metalanguage/type system update, centered around a new approach to metasemantics. This is probably the biggest set of changes since the initial release.\nNew features:\n\nMeta-meta-language (new module, lamb.meta.meta):\n\nMetaTerm: this is a major change/improvement to how constant values (e.g. True) work. A MetaTerm is a direct, immutable reference to a backing python object that provides a metasemantics for the term. This change goes together with an explicit implementation of domain sets of python objects, providing backing domains for all simple types (e.g. type e is backed by strings of a certain kind, SetType is backed by python sets, functions are backed by mappings/callables, etc).\nSimplification guarantees complete simplification when dealing with MetaTerms. This change also allows simplification for quantified expressions with finite domains (by iterating over the type domain).\nEvaluations: much richer support for truth-table-like batch evaluations of boolean expressions. truthtable is a handy wrapper function on this.\nextract_boolean: given an arbitrary metalanguage expression, produce a purely boolean expression together with an assignment filling in the non-boolean parts.\n\nMetalanguage set operations and relations\n\ncore operations: intersection, union, difference. Core relations: equivalence, the various sub/superset relations.\ncorresponding simplification heuristics.\n\nType system features:\n\nAs noted above, the ontology for simple types is new essentially complete, at least for the finite case, by implementing domain sets.\nType domains allow domain restriction in order to work with finite examples. The easiest api for this is the context manager function restrict_domain on atomic types.\nA new type constructor (∀) that unselectively binds type variables in its scope. This is only semi-intended to be user facing, as it isn’t easy to understand. However, this directly supports the next feature:\nSupport for full let-polymorphism via assignments. That is, polymorphic functions in assignments can now have distinct specializations in the same expression (previously they would have to unify to a coherent type; let-polymorphism could only be achieved anonymously via reduction).\n\nMetalanguage “compilation”: expressions with no free variables can now be converted to python code that runs roughly within an order of magnitude of similar code implemented directly in python. In many cases, this is much faster than simplification, and sometimes in a way that matters (especially with quantification in play). There are certain other caveats: finite sets only, equivalence of functions can’t be dynamically determined.\nSimplification and expression manipulation features:\n\nnew module, lamb.meta.ply, hosts various code (new and old) for generic manipulation and introspection on TypedExpr objects.\nterm order normalization for n-ary operations where this is appropriate (e.g. &, |). This normalizes order and structure (to left commutivity). This approach allows keeping strict binary operators, but when appropriate, manipulating them as n-ary sequences.\nmore configurable simplification, with a number of options that may not be used by default. (Roughly building on SymPy’s approach.) For example, the eliminate_sets option will convert set operations/relations to booleans where possible, though this may make formulas more complicated.\n\nError / exception handling and display, especially in magic contexts, is rewritten. New context manager lamb.errors() allows clean handling of lambda notebook-specific errors.\nComposition:\n\ncompose order is now preserved and used in rendering for bottom-up composition.\ncomposition objects now support a function source_tree(), which extracts an underlying nltk-style Tree for display.\n\n\nDocumentation and sample notebooks:\n\nNew documentation for sets, meta-meta-language expressions\nRewritten: Hamblin semantics fragment\n\nFixes, improvements, changes:\n\ntypes and related issues:\n\nmany internal improvements/changes to type inference. One thing to note is that internal type variables will now appear as ? followed by a number, rather than as I variables.\nimprovements to anonymous let-polymorphism, which was previously very non-general\nMany bug fixes to do with polymorphism\n\nimprovements to simplification with recursive Tuple expressions\nimprovements to inference for Partial expressions.\nimprovements to derivations. The most public-facing change is that derivation reasons are now visually aligned with the origin step, not the result step. These objects now better support introspection, as well.\nmany improvements to metalanguage simplification and reduction heuristics.\nimprovements to latex rendering compatibility, including colab (katex) and mathjax 3.\nOlder support code has been removed"
  },
  {
    "objectID": "CHANGELOG.html#rendering-and-metalanguage-updates---2023-09-27",
    "href": "CHANGELOG.html#rendering-and-metalanguage-updates---2023-09-27",
    "title": "Changelog for lambda-notebook",
    "section": "",
    "text": "New features:\n\nsupport rendering in colab\nquicker loading without the kernel (import lamb.auto)\nrefactor metalanguage code: better support for new operators\n\nFixes:\n\nfix several polymorphic type inference issues\nimproved ipython/jupyter rendering"
  },
  {
    "objectID": "CHANGELOG.html#compatibility-fix---2022-06-18",
    "href": "CHANGELOG.html#compatibility-fix---2022-06-18",
    "title": "Changelog for lambda-notebook",
    "section": "",
    "text": "Fix a python 3.10 compatibility bug"
  },
  {
    "objectID": "CHANGELOG.html#vacuity-improvements---2021-10-18",
    "href": "CHANGELOG.html#vacuity-improvements---2021-10-18",
    "title": "Changelog for lambda-notebook",
    "section": "",
    "text": "Fixes, improvements, changes (highlights):\n\ncorrectly pin the right traitlets version"
  },
  {
    "objectID": "CHANGELOG.html#vacuity-improvements---2021-10-18-1",
    "href": "CHANGELOG.html#vacuity-improvements---2021-10-18-1",
    "title": "Changelog for lambda-notebook",
    "section": "",
    "text": "New features:\n\ncomposition rule for index percolation in tree composition\ncomposition rule for vacuous nodes (with content=None)\n\nFixes, improvements, changes (highlights):\n\nimprove and generalize lang.Binder behavior\nenable svgling for internal tree drawing\nimprovements to the relative clause notebook"
  },
  {
    "objectID": "CHANGELOG.html#bugfix-release-python-packaging---2021-10-11",
    "href": "CHANGELOG.html#bugfix-release-python-packaging---2021-10-11",
    "title": "Changelog for lambda-notebook",
    "section": "",
    "text": "This is the first version that was released on PyPI.\nNew features:\n\nadded an explicit changelog in this version. (Older changes in this document are backfilled from commit messages.)\nexperimental support for derivations shown using svgling trees\nfull support for installation in site-packages, better kernel installation\n\nFixes, improvements, changes (highlights):\n\nimprove derivation rendering\nimprove cross-browser compatibility\nimprove error messaging and handling of composition failures"
  },
  {
    "objectID": "CHANGELOG.html#bugfix-release---2018-10-10",
    "href": "CHANGELOG.html#bugfix-release---2018-10-10",
    "title": "Changelog for lambda-notebook",
    "section": "",
    "text": "Documentation and notebooks:\n\nIntensional scope fragment (primarily based on Keshet’s work)\n\nFixes, improvements, changes (highlights):\n\nTest improvements\nPartiality rework\nCI (via Travis)\nrepr improvements"
  },
  {
    "objectID": "CHANGELOG.html#partiality-and-simplification---2017-11-03",
    "href": "CHANGELOG.html#partiality-and-simplification---2017-11-03",
    "title": "Changelog for lambda-notebook",
    "section": "",
    "text": "(Note: in conventional commit terms this should have definitely been a major version bump.)\nNew features:\n\nChange Predicate Abstraction based on Coppock’s version in Semantics Boot Camp (now Coppock and Champollion)\nRecursive simplification for boolean expressions, numbers\nLexical ambiguity in Items\nMetalanguage operator ExistsExact\nInitial implementation of Heim & Kratzer-style presuppositions via partiality\nDisjunctive type constructor, for ad-hoc polymorphism over simple types; and corresponding Disjunction objects in the metalanguage\ntesting infrastructure, random expression generation\n\nDocumentation:\n\nNew introductory demo notebook\nNew fragment: compositional DRT (from Dee Ann Reisinger)\nMetalanguage quick reference\n\nFixes, improvements, changes (highlights):\n\nFixes and improvements to polymorphism, better testing\nImprovements to composition systems, especially tree-based composition\nImprovements to rich reprs"
  },
  {
    "objectID": "CHANGELOG.html#bugfix-update---2016-09-28",
    "href": "CHANGELOG.html#bugfix-update---2016-09-28",
    "title": "Changelog for lambda-notebook",
    "section": "",
    "text": "New feature:\n\nAllow spaces and underscores in Item names\n\nFixes, improvements, changes (highlights):\n\nvarious display fixes\nupdate for nltk 3+\ndocumentation / notebook fixes\nimprovements to packaging"
  },
  {
    "objectID": "CHANGELOG.html#bugfix-update---2016-02-13",
    "href": "CHANGELOG.html#bugfix-update---2016-02-13",
    "title": "Changelog for lambda-notebook",
    "section": "",
    "text": "packaging improvements and fixes"
  },
  {
    "objectID": "CHANGELOG.html#bugfix-update---2016-02-07",
    "href": "CHANGELOG.html#bugfix-update---2016-02-07",
    "title": "Changelog for lambda-notebook",
    "section": "",
    "text": "fix a fragment notebook"
  },
  {
    "objectID": "CHANGELOG.html#polymorphism---2016-02-07",
    "href": "CHANGELOG.html#polymorphism---2016-02-07",
    "title": "Changelog for lambda-notebook",
    "section": "",
    "text": "New features:\n\nSupport for polymorphic types and inference via type variables\nCorresponding metalanguage updates\n\nFixes, improvements, changes (highlights):\n\nImprovements for IPython 3"
  },
  {
    "objectID": "CHANGELOG.html#interim-release---2015-02-09",
    "href": "CHANGELOG.html#interim-release---2015-02-09",
    "title": "Changelog for lambda-notebook",
    "section": "",
    "text": "New features:\n\n%te magic\nnew renderers for recursive / tree-like composition displays\n\nFixes, improvements, changes (highlights):\n\nimprovements to rich reprs\nfixes to reduction"
  },
  {
    "objectID": "CHANGELOG.html#first-public-release---2014-10-06",
    "href": "CHANGELOG.html#first-public-release---2014-10-06",
    "title": "Changelog for lambda-notebook",
    "section": "",
    "text": "This version was aiming at basic intro to semantics feature completeness:\n\nthe lambda notebook IPython kernel\ntypes for a simply-typed lambda calculus\na matching more-or-less complete metalanguage for simply-typed lambda calculus\ncomposition systems, rich repr rendering, integration with nltk Tree\nvarious demo and fragment notebooks\npackaging (now completely deprecated)\n\n(Version control begins 2014-01-01.)"
  },
  {
    "objectID": "demo-for-linguists.html",
    "href": "demo-for-linguists.html",
    "title": "Lambda notebook demo",
    "section": "",
    "text": "Download this notebook for interactive use."
  },
  {
    "objectID": "demo-for-linguists.html#the-role-of-formalism-fragments-in-semantics",
    "href": "demo-for-linguists.html#the-role-of-formalism-fragments-in-semantics",
    "title": "Lambda notebook demo",
    "section": "2.1 The role of formalism & fragments in semantics",
    "text": "2.1 The role of formalism & fragments in semantics\nWhat does formal mean in semantics? What properties should a theory have?\n\nMathematically precise (lambda calculus, type theory, logic, model theory(?), …)\nComplete (covers “all” the relevant data).\nPredictive (like any scientific theory).\nConsistent, or at least compatible (with itself, analyses of other phenomena, some unifying conception of the grammar).\n\nThe method of fragments (Partee 1979; Partee and Hendriks 1997) provides a structure for meeting these criteria.\n\nPartee, Barbara H., and Herman L. W. Hendriks. 1997. “Montague Grammar.” In Handbook of Logic and Language, edited by Johan van Benthem and Alice G. B. ter Meulen, 5–91. Elsevier; MIT Press. https://doi.org/10.1016/B978-044481714-3/50004-7.\n\nPaper with a fragment provides a working system. (Probably.)\nExplicit outer bound for empirical coverage.\nIntegration with a particular theory of grammar. (To some extent.)\nExplicit answer to many detailed questions not necessarily dealt with in the text.\n\nClaim: fragments are a method of replicability, similar to a computational modeller providing their model.\n\nTo be clear, a fragment is neither necessary nor sufficient for having a good theory / analysis / paper…\n\nAdditional benefit: useful internal check for researcher.\n\n“…But I feel strongly that it is important to try to [work with fully explicit fragments] periodically, because otherwise it is extremely easy to think that you have a solution to a problem when in fact you don’t.” (Partee 1979, p. 41)"
  },
  {
    "objectID": "demo-for-linguists.html#the-challenges-of-fragments",
    "href": "demo-for-linguists.html#the-challenges-of-fragments",
    "title": "Lambda notebook demo",
    "section": "2.2 The challenges of fragments",
    "text": "2.2 The challenges of fragments\nPart 1 of the above quote:\n\n“It can be very frustrating to try to specify frameworks and fragments explicitly; this project has not been entirely rewarding. I would not recommend that one always work with the constraint of full explicitness.” (Ibid.)\n\n\nFragments can be tedious and time-consuming to write (not to mention hard).\nFragments as traditionally written are in practice not easy for a reader to use.\n\nDense/unapproachable. With exactness can come a huge chunk of hard-to-digest formalism. E.g. Partee (1979), the fragment is about 10% of the paper.\nMonolithic/non-modular. For the specified sublanguage, everything is specified. Outside the bounds of the sublanguage, nothing is specified. How does the theory fit in with others?\nExact opposite of the modern method – researchers typically hold most aspects of the grammar constant (implicitly) while changing a few key points. (See e.g., the introduction to Portner and Partee 2002 for discussion.)\n\n\n\nPartee, Barbara H. 1979. “Constraining Transformational Montague Grammar: A Framework and a Fragment.” In Linguistics, Philosophy, and Montague Grammar, edited by S. Davis and M. Mithun, 51–101. University of Texas Press. https://doi.org/10.7560/746251-004.\n\nPortner, Paul, and Barbara Partee, eds. 2002. Formal Semantics: The Essential Readings. Blackwell Publishing.\nSummary: In practice, the typical payoff for neither the reader nor the writer of a fragment exceeded the effort."
  },
  {
    "objectID": "demo-for-linguists.html#part-1-flexible-typed-metalanguage",
    "href": "demo-for-linguists.html#part-1-flexible-typed-metalanguage",
    "title": "Lambda notebook demo",
    "section": "3.1 Part 1: flexible typed metalanguage",
    "text": "3.1 Part 1: flexible typed metalanguage\nThe metalanguage infrastructure is a set of python classes that implement the building blocks of logical expressions, lambda terms, and various other formal objects, as well as complex formulas built from these pieces. This rests on an implementation of a framework for type systems that matches what semanticists tend to assume.\nPreface cell with %%lamb to enter metalanguage formulas directly. The following cell defines a variable x that has type e, and exports it to the notebook’s environment.\n\n%%lamb reset\nx = x_e\n\n\\({x}_{e}\\:=\\:{x}_{e}\\)\n\n\n\nx.type\n\n\\(e\\)\n\n\nThis next cell defines some variables whose values are more complex object – in fact, functions in the typed lambda calculus.\n\n%%lamb\ntest1 = L p_t : L x_e : P_&lt;e,t&gt;(x) & p # based on a Partee et al example\ntest1b = L x_e : P_&lt;e,t&gt;(x) & Q_&lt;e,t&gt;(x)\nt2 = Q_&lt;e,t&gt;(x_e)\n\n\\({test1}_{\\left\\langle{}t,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}\\:=\\:\\lambda{} p_{t} \\: . \\: \\lambda{} x_{e} \\: . \\: {p} \\wedge{} {P}({x})\\) \\({test1b}_{\\left\\langle{}e,t\\right\\rangle{}}\\:=\\:\\lambda{} x_{e} \\: . \\: {P}({x}) \\wedge{} {Q}({x})\\) \\({t2}_{t}\\:=\\:{Q}({x}_{e})\\)\n\n\nThese are now registered as variables in the python namespace and can be manipulated directly. A typed lambda calculus is fully implemented with all that that entails – e.g. the value of test1 includes the whole syntactic structure of the formula, its type, etc. and can be used in constructing new formulas. The following cells build a complex function-argument formula, and following that, does the reduction.\nNotice that beta reduction works properly, i.e. bound \\(x\\) in the function is renamed in order to avoid collision with the free x in the argument. (test1b is based on an example illustrating alpha conversion from Partee, Meulen, and Wall 1993.)\n\nPartee, Barbara H., Alice ter Meulen, and Robert Wall. 1993. Mathematical Methods in Linguistics. Dordrecht: Kluwer. https://doi.org/10.1007/978-94-009-2213-6.\n\ntest1(t2) # construct a complex function-argument expression\n\n\\({[\\lambda{} p_{t} \\: . \\: \\lambda{} x_{e} \\: . \\: {p} \\wedge{} {P}({x})]}({Q}({x}_{e}))\\)\n\n\n\ntest1(t2).reduce() # do reduction on that expression\n\n\\(\\lambda{} x1_{e} \\: . \\: {Q}({x}_{e}) \\wedge{} {P}({x1})\\)\n\n\n\n%%lamb\ncatf = L x_e: Cat_&lt;e,t&gt;(x)\ndogf = λx: Dog_&lt;e,t&gt;(x_e)\n\n\\({catf}_{\\left\\langle{}e,t\\right\\rangle{}}\\:=\\:\\lambda{} x_{e} \\: . \\: {Cat}({x})\\) \\({dogf}_{\\left\\langle{}e,t\\right\\rangle{}}\\:=\\:\\lambda{} x_{e} \\: . \\: {Dog}({x})\\)\n\n\n\ndisplay(catf(x), (catf(x)).type)\n\n\\({[\\lambda{} x_{e} \\: . \\: {Cat}({x})]}({x}_{e})\\)\n\n\n\\(t\\)\n\n\n\ncatf.type\n\n\\(\\left\\langle{}e,t\\right\\rangle{}\\)\n\n\nType checking of course is a part of all this. If the types don’t match, the computation will throw a TypeMismatch exception. The following cell uses python syntax to catch and print such errors.\n\nwith lamb.errors():\n    test1(x) # function is type &lt;t,&lt;e,t&gt;&gt; so will trigger a type mismatch.\n\nTypeMismatch: (λ p_t: (λ x_e: (p_t & P_&lt;e,t&gt;(x_e))))/&lt;t,&lt;e,t&gt;&gt; and x_e conflict (Incompatible function-argument types &lt;t,&lt;e,t&gt;&gt; and e)\n\n\nA more complex expression:\n\n%%lamb\np2 = (Cat_&lt;e,t&gt;(x_e) & p_t) &gt;&gt; (Exists y: Dog_&lt;e,t&gt;(y_e))\n\n\\({p2}_{t}\\:=\\:({p}_{t} \\wedge{} {Cat}({x}_{e})) \\rightarrow{} (\\exists{} y_{e} \\: . \\: {Dog}({y}))\\)\n\n\nWhat is going on behind the scenes? The objects manipulated are recursively structured python objects (of class TypedExpr). Each layer of recursion stores information about the kind of metalanguage expression it is, as well as its parts.\nMany straightforward expressions can be parsed. Most expressions are created using a call to TypedExpr.factory, which is abbreviated as “te” in the following examples. The %%lamb magic is calling this behind the scenes.\n\nx = %te x_e\nx\n\n\\({x}_{e}\\)\n\n\nVarious convenience python operators are overloaded, including functional calls. Here is an example repeated from earlier in two forms:\n\n%%lamb\np2 = (Cat_&lt;e,t&gt;(x_e) & p_t) &gt;&gt; (Exists y: Dog_&lt;e,t&gt;(y_e))\n\n\\({p2}_{t}\\:=\\:({p}_{t} \\wedge{} {Cat}({x}_{e})) \\rightarrow{} (\\exists{} y_{e} \\: . \\: {Dog}({y}))\\)\n\n\n\np2 = (te(\"Cat_&lt;e,t&gt;(x)\") & te(\"p_t\")) &gt;&gt; te(\"(Exists y: Dog_&lt;e,t&gt;(y_e))\")\np2\n\n\\(({Cat}({x}_{e}) \\wedge{} {p}_{t}) \\rightarrow{} (\\exists{} y_{e} \\: . \\: {Dog}({y}))\\)\n\n\nLet’s examine in detail what happens when a function and argument combine.\n\ncatf = meta.LFun(te(\"x_e\"), te(\"Cat(x_e)\"))\ncatf\n\nINFO (core): Coerced guessed type for 'Cat_t' into &lt;e,t&gt;, to match argument 'x_e'\n\n\n\\(\\lambda{} x_{e} \\: . \\: {Cat}({x})\\)\n\n\n\ncatf(te(\"y_e\"))\n\n\\({[\\lambda{} x_{e} \\: . \\: {Cat}({x})]}({y}_{e})\\)\n\n\nBuilding a function-argument expression builds a complex, unreduced expression. This can be explicitly reduced (note that the reduce_all() function would be used to apply reduction recursively):\n\ncatf(te(\"y_e\")).reduce()\n\n\\({Cat}({y}_{e})\\)\n\n\n\n(catf(te(\"y_e\")).reduce()).derivation\n\n${[\\lambda{} x_{e} \\: . \\: {Cat}({x})]}({y}_{e})$Reduction 1. ${Cat}({y}_{e})$\n\n\nThe metalanguage supports type polymorphism. For example, we can define a function whose input type is a type variable (X) and then combine that function with a concrete type, to force type narrowing:\n\n%lamb ttest = L x_X : P_&lt;X,t&gt;(x)\n%lamb tvar = y_t\nttest(tvar)\n\n\\({ttest}_{\\left\\langle{}X,t\\right\\rangle{}}\\:=\\:\\lambda{} x_{X} \\: . \\: {P}_{\\left\\langle{}X,t\\right\\rangle{}}({x})\\)\n\n\n\\({tvar}_{t}\\:=\\:{y}_{t}\\)\n\n\n\\({[\\lambda{} x_{t} \\: . \\: {P}_{\\left\\langle{}t,t\\right\\rangle{}}({x})]}({y}_{t})\\)\n\n\nOther operators not illustrated here include set theoretic expressions, tools for building partial functions and denotations, a rich approach to “meta-meta-language”, restricted quantifiers, and more.\n\n3.1.1 Model theory and evaluation\nThe lambda notebook supports model theory and evaluation of extensional formulas.\n\nm = meta.Model({'A': '_c1',\n                'B': '_c2',\n                'C': '_c1',\n                'P': {'A', 'B'}},\n               domain={'_c1', '_c2', '_c3'})\nm\n\nDomain: \\(D_{e} = \\{\\textsf{c1}_{e}, \\textsf{c2}_{e}, \\textsf{c3}_{e}\\}\\)Valuations:\\(\\left[\\begin{array}{lll} A & \\rightarrow & \\textsf{c1}_{e} \\\\\nB & \\rightarrow & \\textsf{c2}_{e} \\\\\nC & \\rightarrow & \\textsf{c1}_{e} \\\\\nP & \\rightarrow & \\textsf{Fun[\\{A,B\\}]}_{\\left\\langle{}e,t\\right\\rangle{}} \\\\ \\end{array}\\right]\\)\n\n\n\nm.evaluate(te(\"Exists x_e : P_&lt;e,t&gt;(x)\")).derivation.trace()\n\n$\\exists{} x_{e} \\: . \\: {P}({x})$Assignment substitution 1. $\\exists{} x_{e} \\: . \\: {\\textsf{P}}^{\\text{\\textsf{[meta]}}}({x})$verifier for ∃x${\\textsf{P}}^{\\text{\\textsf{[meta]}}}({x}_{e})$Assignment substitution 1. ${\\textsf{P}}^{\\text{\\textsf{[meta]}}}({x}^{A/\\textsf{c1}}_{e})$Reduction 2. $\\textsf{True}$ 2. $\\textsf{True}$\n\n\n\nm.evaluate(te(\"Forall x_e : P_&lt;e,t&gt;(x)\")).derivation.trace()\n\n$\\forall{} x_{e} \\: . \\: {P}({x})$Assignment substitution 1. $\\forall{} x_{e} \\: . \\: {\\textsf{P}}^{\\text{\\textsf{[meta]}}}({x})$counterexample for ∀x${\\textsf{P}}^{\\text{\\textsf{[meta]}}}({x}_{e})$Assignment substitution 1. ${\\textsf{P}}^{\\text{\\textsf{[meta]}}}({x}^{\\textsf{c3}}_{e})$Reduction 2. $\\textsf{False}$ 2. $\\textsf{False}$"
  },
  {
    "objectID": "demo-for-linguists.html#part-2-composition-systems-for-an-object-language",
    "href": "demo-for-linguists.html#part-2-composition-systems-for-an-object-language",
    "title": "Lambda notebook demo",
    "section": "3.2 Part 2: composition systems for an object language",
    "text": "3.2 Part 2: composition systems for an object language\nOn top of the metalanguage are ‘composition systems’ for modeling (step-by-step) semantic composition in an object language such as English. This is the part of the lambda notebook that tracks and manipulates mappings between object language elements (words, trees, etc) and denotations in the metalanguage.\nA composition system at its core consists of a set of composition rules; the following cell defines a simple composition system that will be familiar to anyone who has taken a basic course in compositional semantics. (See among others, Heim and Kratzer 1998; Coppock and Champollion 2024)\n\n# none of this is strictly necessary, the built-in library already provides effectively this system.\nfa = lang.BinaryCompositionOp(\"FA\", lang.fa_fun, reduce=True)\npm = lang.BinaryCompositionOp(\"PM\", lang.pm_fun, commutative=True, reduce=True)\npa = lang.BinaryCompositionOp(\"PA\", lang.pa_fun, allow_none=True)\ndemo_hk_system = lang.CompositionSystem(name=\"demo system\", rules=[fa, pm, pa])\nlang.set_system(demo_hk_system)\ndemo_hk_system\n\nComposition system 'demo system'Operations: {    Binary composition rule FA, built on python function 'lamb.lang.fa_fun'    Binary composition rule PM, built on python function 'lamb.lang.pm_fun'    Binary composition rule PA, built on python function 'lamb.lang.pa_fun'}\n\n\nExpressing denotations is done in a %%lamb cell, and almost always begins with lexical items. The following cell defines several lexical items that will be familiar from introductory exercises in the Heim and Kratzer (1998) textbook.\n\n%%lamb\n||cat|| = L x_e: Cat_&lt;e,t&gt;(x)\n||gray|| = L x_e: Gray_&lt;e,t&gt;(x)\n||john|| = John_e\n||julius|| = Julius_e\n||inP|| = L x_e : L y_e : In_&lt;(e,e),t&gt;(y, x) # `in` is a reserved word in python\n||texas|| = Texas_e\n||isV|| = L p_&lt;e,t&gt; : p # `is` is a reserved word in python\n\n\\([\\![\\text{\\textbf{cat}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {Cat}({x})\\) \\([\\![\\text{\\textbf{gray}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {Gray}({x})\\) \\([\\![\\text{\\textbf{john}}]\\!]^{}_{e} \\:=\\: {John}_{e}\\) \\([\\![\\text{\\textbf{julius}}]\\!]^{}_{e} \\:=\\: {Julius}_{e}\\) \\([\\![\\text{\\textbf{inP}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: \\lambda{} y_{e} \\: . \\: {In}({y}, {x})\\) \\([\\![\\text{\\textbf{texas}}]\\!]^{}_{e} \\:=\\: {Texas}_{e}\\) \\([\\![\\text{\\textbf{isV}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} p_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: {p}\\)\n\n\nAll object-language representations implement the interface lamb.lang.Composable, including lexical items as well as the complex results shown below. In type-driven mode, composition is triggered by using the ‘*’ operator on a Composable. This searches over the available composition operations in the system to see if any results can be had. Given their types, we expect inP and texas above to be able to compose using the FA rule:\n\ninP * texas\n\n1 composition path. Result:     [0]: \\([\\![\\text{\\textbf{[inP texas]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} y_{e} \\: . \\: {In}({y}, {Texas}_{e})\\)\n\n\nOn the other hand isV is looking for a property, so we shouldn’t expect succesful composition with a type e element.\n\njulius * isV # will fail due to type mismatches\n\nComposition of “[julius isV]” failed:     TypeMismatch: \\([\\![\\text{\\textbf{julius}}]\\!]^{}_{e} \\:=\\: {Julius}_{e}\\) and \\([\\![\\text{\\textbf{isV}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} p_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: {p}\\) conflict (Function Application needs a matching function and argument)     TypeMismatch: \\([\\![\\text{\\textbf{isV}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} p_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: {p}\\) and \\([\\![\\text{\\textbf{julius}}]\\!]^{}_{e} \\:=\\: {Julius}_{e}\\) conflict (Function Application needs a matching function and argument)     TypeMismatch: \\([\\![\\text{\\textbf{julius}}]\\!]^{}_{e} \\:=\\: {Julius}_{e}\\) and \\([\\![\\text{\\textbf{isV}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} p_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: {p}\\) conflict (Predicate Modification needs property types)     Composition failure on: \\([\\![\\text{\\textbf{julius}}]\\!]^{}_{e} \\:=\\: {Julius}_{e}\\) * \\([\\![\\text{\\textbf{isV}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} p_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: {p}\\) (Predicate Abstraction requires a valid binder)     Composition failure on: \\([\\![\\text{\\textbf{isV}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} p_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: {p}\\) * \\([\\![\\text{\\textbf{julius}}]\\!]^{}_{e} \\:=\\: {Julius}_{e}\\) (Predicate Abstraction requires a valid binder)\n\n\nComposition results are Composables as well, and so can be further composed:\n\nsentence1 = julius * (isV * (inP * texas))\ndisplay(sentence1[0].source_tree())\nsentence1\n\n\n\n\n\n\n\n\n1 composition path. Result:     [0]: \\([\\![\\text{\\textbf{[julius [isV [inP texas]]]}}]\\!]^{}_{t} \\:=\\: {In}({Julius}_{e}, {Texas}_{e})\\)\n\n\n\nsentence1.trace()\n\nFull composition trace. 1 path:     Step 1: \\([\\![\\text{\\textbf{julius}}]\\!]^{}_{e} \\:=\\: {Julius}_{e}\\)     Step 2: \\([\\![\\text{\\textbf{isV}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} p_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: {p}\\)     Step 3: \\([\\![\\text{\\textbf{inP}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: \\lambda{} y_{e} \\: . \\: {In}({y}, {x})\\)     Step 4: \\([\\![\\text{\\textbf{texas}}]\\!]^{}_{e} \\:=\\: {Texas}_{e}\\)     Step 5: \\([\\![\\text{\\textbf{inP}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}\\) * \\([\\![\\text{\\textbf{texas}}]\\!]^{}_{e}\\) leads to: \\([\\![\\text{\\textbf{[inP texas]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} y_{e} \\: . \\: {In}({y}, {Texas}_{e})\\) [by FA]     Step 6: \\([\\![\\text{\\textbf{isV}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}\\) * \\([\\![\\text{\\textbf{[inP texas]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}\\) leads to: \\([\\![\\text{\\textbf{[isV [inP texas]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} y_{e} \\: . \\: {In}({y}, {Texas}_{e})\\) [by FA]     Step 7: \\([\\![\\text{\\textbf{julius}}]\\!]^{}_{e}\\) * \\([\\![\\text{\\textbf{[isV [inP texas]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}\\) leads to: \\([\\![\\text{\\textbf{[julius [isV [inP texas]]]}}]\\!]^{}_{t} \\:=\\: {In}({Julius}_{e}, {Texas}_{e})\\) [by FA]\n\n\nComposition will find all possible paths, but in the current example there are no ambiguities. (Note: the metalanguage by default normalizes the order of conjuncts alphabetically, so the order in the output of PM is independent of what composes with what. This is why the operation is marked “commutative” when defined earlier – so the composition system knows it doesn’t need to bother with both orders.)\n\ngray * cat\n\n1 composition path. Result:     [0]: \\([\\![\\text{\\textbf{[gray cat]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Gray}({x})\\)\n\n\n\ngray * (cat * (inP * texas))\n\n1 composition path. Result:     [0]: \\([\\![\\text{\\textbf{[gray [cat [inP texas]]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Gray}({x}) \\wedge{} {In}({x}, {Texas}_{e})\\)\n\n\n\na = lang.Item(\"a\", isV.content) # identity function for copula as well\nisV * (a * (gray * cat * (inP * texas)))\n\n1 composition path. Result:     [0]: \\([\\![\\text{\\textbf{[isV [a [[gray cat] [inP texas]]]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Gray}({x}) \\wedge{} {In}({x}, {Texas}_{e})\\)\n\n\n\nnp = ((gray * cat) * (inP * texas))\nvp = (isV * (a * np))\nsentence2 = julius * vp\nsentence2\n\n1 composition path. Result:     [0]: \\([\\![\\text{\\textbf{[julius [isV [a [[gray cat] [inP texas]]]]]}}]\\!]^{}_{t} \\:=\\: {Cat}({Julius}_{e}) \\wedge{} {Gray}({Julius}_{e}) \\wedge{} {In}({Julius}_{e}, {Texas}_{e})\\)\n\n\n\nsentence1.results[0]\n\n\\([\\![\\text{\\textbf{[julius [isV [inP texas]]]}}]\\!]^{}_{t} \\:=\\: {In}({Julius}_{e}, {Texas}_{e})\\)\n\n\n\nsentence1.tree()\n\n1 composition path:$[\\![\\text{\\textbf{julius}}]\\!]^{}_{e}$${Julius}_{e}$*$[\\![\\text{\\textbf{isV}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}$$\\lambda{} p_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: {p}$*$[\\![\\text{\\textbf{inP}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: \\lambda{} y_{e} \\: . \\: {In}({y}, {x})$*$[\\![\\text{\\textbf{texas}}]\\!]^{}_{e}$${Texas}_{e}$[FA]$[\\![\\text{\\textbf{[inP texas]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} y_{e} \\: . \\: {In}({y}, {Texas}_{e})$[FA]$[\\![\\text{\\textbf{[isV [inP texas]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} y_{e} \\: . \\: {In}({y}, {Texas}_{e})$[FA]$[\\![\\text{\\textbf{[julius [isV [inP texas]]]}}]\\!]^{}_{t}$${In}({Julius}_{e}, {Texas}_{e})$\n\n\n\nsentence2.tree()\n\n1 composition path:$[\\![\\text{\\textbf{julius}}]\\!]^{}_{e}$${Julius}_{e}$*$[\\![\\text{\\textbf{isV}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}$$\\lambda{} p_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: {p}$*$[\\![\\text{\\textbf{a}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}$$\\lambda{} p_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: {p}$*$[\\![\\text{\\textbf{gray}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Gray}({x})$*$[\\![\\text{\\textbf{cat}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x})$[PM]$[\\![\\text{\\textbf{[gray cat]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Gray}({x})$*$[\\![\\text{\\textbf{inP}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: \\lambda{} y_{e} \\: . \\: {In}({y}, {x})$*$[\\![\\text{\\textbf{texas}}]\\!]^{}_{e}$${Texas}_{e}$[FA]$[\\![\\text{\\textbf{[inP texas]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} y_{e} \\: . \\: {In}({y}, {Texas}_{e})$[PM]$[\\![\\text{\\textbf{[[gray cat] [inP texas]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Gray}({x}) \\wedge{} {In}({x}, {Texas}_{e})$[FA]$[\\![\\text{\\textbf{[a [[gray cat] [inP texas]]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Gray}({x}) \\wedge{} {In}({x}, {Texas}_{e})$[FA]$[\\![\\text{\\textbf{[isV [a [[gray cat] [inP texas]]]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Gray}({x}) \\wedge{} {In}({x}, {Texas}_{e})$[FA]$[\\![\\text{\\textbf{[julius [isV [a [[gray cat] [inP texas]]]]]}}]\\!]^{}_{t}$${Cat}({Julius}_{e}) \\wedge{} {Gray}({Julius}_{e}) \\wedge{} {In}({Julius}_{e}, {Texas}_{e})$\n\n\nHere’s a well-known example exercise from Heim and Kratzer (1998) (names different):\n(1) Julius is a gray cat in Texas fond of John.\nCalculating the denotation of this is relatively straightforward, as long as the lexical items and order of composition are correct.\n\nfond = lang.Item(\"fond\", \"L x_e : L y_e : Fond(y)(x)\")\nofP = lang.Item(\"of\", \"L x_e : x\")\nsentence3 = julius * (isV * (a * (((gray * cat) * (inP * texas)) * (fond * (ofP * john)))))\ndisplay(sentence3[0].source_tree())\nsentence3\n\nINFO (core): Coerced guessed type for 'Fond_t' into &lt;e,t&gt;, to match argument 'y_e'\nINFO (core): Coerced guessed type for 'Fond_&lt;e,t&gt;(y_e)' into &lt;e,t&gt;, to match argument 'x_e'\n\n\n\n\n\n\n\n\n\n1 composition path. Result:     [0]: \\([\\![\\text{\\textbf{[julius [isV [a [[[gray cat] [inP texas]] [fond [of john]]]]]]}}]\\!]^{}_{t} \\:=\\: {Cat}({Julius}_{e}) \\wedge{} {Fond}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}({Julius}_{e})({John}_{e}) \\wedge{} {Gray}({Julius}_{e}) \\wedge{} {In}({Julius}_{e}, {Texas}_{e})\\)\n\n\n\nsentence3.tree()\n\n1 composition path:$[\\![\\text{\\textbf{julius}}]\\!]^{}_{e}$${Julius}_{e}$*$[\\![\\text{\\textbf{isV}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}$$\\lambda{} p_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: {p}$*$[\\![\\text{\\textbf{a}}]\\!]^{}_{\\left\\langle{}\\left\\langle{}e,t\\right\\rangle{},\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}$$\\lambda{} p_{\\left\\langle{}e,t\\right\\rangle{}} \\: . \\: {p}$*$[\\![\\text{\\textbf{gray}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Gray}({x})$*$[\\![\\text{\\textbf{cat}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x})$[PM]$[\\![\\text{\\textbf{[gray cat]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Gray}({x})$*$[\\![\\text{\\textbf{inP}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: \\lambda{} y_{e} \\: . \\: {In}({y}, {x})$*$[\\![\\text{\\textbf{texas}}]\\!]^{}_{e}$${Texas}_{e}$[FA]$[\\![\\text{\\textbf{[inP texas]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} y_{e} \\: . \\: {In}({y}, {Texas}_{e})$[PM]$[\\![\\text{\\textbf{[[gray cat] [inP texas]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Gray}({x}) \\wedge{} {In}({x}, {Texas}_{e})$*$[\\![\\text{\\textbf{fond}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: \\lambda{} y_{e} \\: . \\: {Fond}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}({y})({x})$*$[\\![\\text{\\textbf{of}}]\\!]^{}_{\\left\\langle{}e,e\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {x}$*$[\\![\\text{\\textbf{john}}]\\!]^{}_{e}$${John}_{e}$[FA]$[\\![\\text{\\textbf{[of john]}}]\\!]^{}_{e}$${John}_{e}$[FA]$[\\![\\text{\\textbf{[fond [of john]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} y_{e} \\: . \\: {Fond}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}({y})({John}_{e})$[PM]$[\\![\\text{\\textbf{[[[gray cat] [inP texas]] [fond [of john]]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Fond}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}({x})({John}_{e}) \\wedge{} {Gray}({x}) \\wedge{} {In}({x}, {Texas}_{e})$[FA]$[\\![\\text{\\textbf{[a [[[gray cat] [inP texas]] [fond [of john]]]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Fond}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}({x})({John}_{e}) \\wedge{} {Gray}({x}) \\wedge{} {In}({x}, {Texas}_{e})$[FA]$[\\![\\text{\\textbf{[isV [a [[[gray cat] [inP texas]] [fond [of john]]]]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Fond}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}({x})({John}_{e}) \\wedge{} {Gray}({x}) \\wedge{} {In}({x}, {Texas}_{e})$[FA]$[\\![\\text{\\textbf{[julius [isV [a [[[gray cat] [inP texas]] [fond [of john]]]]]]}}]\\!]^{}_{t}$${Cat}({Julius}_{e}) \\wedge{} {Fond}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}({Julius}_{e})({John}_{e}) \\wedge{} {Gray}({Julius}_{e}) \\wedge{} {In}({Julius}_{e}, {Texas}_{e})$\n\n\nThe Composite class supports indexing, so we can pull out subparts of a derivaiton:\n\nparse_tree3 = sentence3.results[0]\nparse_tree3[1][1][1].tree()\n\n$[\\![\\text{\\textbf{gray}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Gray}({x})$*$[\\![\\text{\\textbf{cat}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x})$[PM]$[\\![\\text{\\textbf{[gray cat]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Gray}({x})$*$[\\![\\text{\\textbf{inP}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: \\lambda{} y_{e} \\: . \\: {In}({y}, {x})$*$[\\![\\text{\\textbf{texas}}]\\!]^{}_{e}$${Texas}_{e}$[FA]$[\\![\\text{\\textbf{[inP texas]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} y_{e} \\: . \\: {In}({y}, {Texas}_{e})$[PM]$[\\![\\text{\\textbf{[[gray cat] [inP texas]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Gray}({x}) \\wedge{} {In}({x}, {Texas}_{e})$*$[\\![\\text{\\textbf{fond}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: \\lambda{} y_{e} \\: . \\: {Fond}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}({y})({x})$*$[\\![\\text{\\textbf{of}}]\\!]^{}_{\\left\\langle{}e,e\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {x}$*$[\\![\\text{\\textbf{john}}]\\!]^{}_{e}$${John}_{e}$[FA]$[\\![\\text{\\textbf{[of john]}}]\\!]^{}_{e}$${John}_{e}$[FA]$[\\![\\text{\\textbf{[fond [of john]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} y_{e} \\: . \\: {Fond}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}({y})({John}_{e})$[PM]$[\\![\\text{\\textbf{[[[gray cat] [inP texas]] [fond [of john]]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Fond}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}({x})({John}_{e}) \\wedge{} {Gray}({x}) \\wedge{} {In}({x}, {Texas}_{e})$\n\n\nThere is support for traces and indexed pronouns, using a version of the Predicate Abstraction (PA) rule (based on the version in Coppock and Champollion 2024).\n\nCoppock, Elizabeth, and Lucas Champollion. 2024. “Invitation to Formal Semantics.” Lecture notes, BU and NYU. http://eecoppock.info/bootcamp/semantics-boot-camp.pdf.\n\nbinder = lang.Binder(23)\nbinder2 = lang.Binder(5)\nt = lang.Trace(23, types.type_e)\nt2 = lang.Trace(5)\ndisplay(t, t2, binder)\n\n\\([\\![\\text{\\textbf{t}}_{23}]\\!]^{}_{e} \\:=\\: {var23}_{e}\\)\n\n\n\\([\\![\\text{\\textbf{t}}_{5}]\\!]^{}_{e} \\:=\\: {var5}_{e}\\)\n\n\n\\([\\![\\text{\\textbf{23}}]\\!]^{}\\text{ [vacuous]}\\)\n\n\n\n((t * gray))\n\n1 composition path. Result:     [0]: \\([\\![\\text{\\textbf{[t23 gray]}}]\\!]^{}_{t} \\:=\\: {Gray}({var23}_{e})\\)\n\n\n\nb1 = (binder * (binder2 * (t * (inP * t2))))\nb2 = (binder2 * (binder * (t * (inP * t2))))\ndisplay(b1, b2)\n\n1 composition path. Result:     [0]: \\([\\![\\text{\\textbf{[23 [5 [t23 [inP t5]]]]}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} x1_{e} \\: . \\: \\lambda{} x_{e} \\: . \\: {In}({x1}, {x})\\)\n\n\n1 composition path. Result:     [0]: \\([\\![\\text{\\textbf{[5 [23 [t23 [inP t5]]]]}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} x1_{e} \\: . \\: \\lambda{} x_{e} \\: . \\: {In}({x}, {x1})\\)\n\n\n\nb1.trace()\n\nFull composition trace. 1 path:     Step 1: \\([\\![\\text{\\textbf{23}}]\\!]^{}\\text{ [vacuous]}\\)     Step 2: \\([\\![\\text{\\textbf{5}}]\\!]^{}\\text{ [vacuous]}\\)     Step 3: \\([\\![\\text{\\textbf{t}}_{23}]\\!]^{}_{e} \\:=\\: {var23}_{e}\\)     Step 4: \\([\\![\\text{\\textbf{inP}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: \\lambda{} y_{e} \\: . \\: {In}({y}, {x})\\)     Step 5: \\([\\![\\text{\\textbf{t}}_{5}]\\!]^{}_{e} \\:=\\: {var5}_{e}\\)     Step 6: \\([\\![\\text{\\textbf{inP}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}\\) * \\([\\![\\text{\\textbf{t}}_{5}]\\!]^{}_{e}\\) leads to: \\([\\![\\text{\\textbf{[inP t5]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} y_{e} \\: . \\: {In}({y}, {var5}_{e})\\) [by FA]     Step 7: \\([\\![\\text{\\textbf{t}}_{23}]\\!]^{}_{e}\\) * \\([\\![\\text{\\textbf{[inP t5]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}\\) leads to: \\([\\![\\text{\\textbf{[t23 [inP t5]]}}]\\!]^{}_{t} \\:=\\: {In}({var23}_{e}, {var5}_{e})\\) [by FA]     Step 8: \\([\\![\\text{\\textbf{5}}]\\!]^{}\\) * \\([\\![\\text{\\textbf{[t23 [inP t5]]}}]\\!]^{}_{t}\\) leads to: \\([\\![\\text{\\textbf{[5 [t23 [inP t5]]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {In}({var23}_{e}, {x})\\) [by PA]     Step 9: \\([\\![\\text{\\textbf{23}}]\\!]^{}\\) * \\([\\![\\text{\\textbf{[5 [t23 [inP t5]]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}\\) leads to: \\([\\![\\text{\\textbf{[23 [5 [t23 [inP t5]]]]}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}} \\:=\\: \\lambda{} x1_{e} \\: . \\: \\lambda{} x_{e} \\: . \\: {In}({x1}, {x})\\) [by PA]\n\n\n\nb1.results[0].tree()\n\n$[\\![\\text{\\textbf{23}}]\\!]^{}$[idx: 23]*$[\\![\\text{\\textbf{5}}]\\!]^{}$[idx: 5]*$[\\![\\text{\\textbf{t}}_{23}]\\!]^{}_{e}$${var23}_{e}$*$[\\![\\text{\\textbf{inP}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: \\lambda{} y_{e} \\: . \\: {In}({y}, {x})$*$[\\![\\text{\\textbf{t}}_{5}]\\!]^{}_{e}$${var5}_{e}$[FA]$[\\![\\text{\\textbf{[inP t5]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} y_{e} \\: . \\: {In}({y}, {var5}_{e})$[FA]$[\\![\\text{\\textbf{[t23 [inP t5]]}}]\\!]^{}_{t}$${In}({var23}_{e}, {var5}_{e})$[PA]$[\\![\\text{\\textbf{[5 [t23 [inP t5]]]}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {In}({var23}_{e}, {x})$[PA]$[\\![\\text{\\textbf{[23 [5 [t23 [inP t5]]]]}}]\\!]^{}_{\\left\\langle{}e,\\left\\langle{}e,t\\right\\rangle{}\\right\\rangle{}}$$\\lambda{} x1_{e} \\: . \\: \\lambda{} x_{e} \\: . \\: {In}({x1}, {x})$\n\n\n\n3.2.1 Composition in tree structures\nIn many contexts it is natural to just use bottom-up composition, especially given the implementation of the PA rule. However, the lambda notebook supports arbtirarily-sequenced composition in tree structures, with deferred composition when missing bottom-up information. This uses Tree objects with an interface designed after those in the nltk package. In these derivations, you can see some of the support for inference over variable types. This composition system more directly matches the classic one presented in Heim and Kratzer (1998).\n\nHeim, Irene, and Angelika Kratzer. 1998. Semantics in Generative Grammar. Blackwell.\n\nlang.set_system(lang.hk_system)\n\n\n%%lamb\n||gray|| = L x_e : Gray_&lt;e,t&gt;(x)\n||cat|| = L x_e : Cat_&lt;e,t&gt;(x)\n\n\\([\\![\\text{\\textbf{gray}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {Gray}({x})\\) \\([\\![\\text{\\textbf{cat}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {Cat}({x})\\)\n\n\n\nt2 = Tree(\"S\", [\"NP\", \"VP\"])\nt2\n\n\n\n\n\n\n\n\nWe can do composition in this tree fragment, but the leaf nodes (not being in the lexicon) are treated as placeholders. They are accordingly assigned polymorphic types.\n\n(The type \\(\\forall X\\) is a type that can be anything at all; this gets narrowed by each possible composition rule that could apply to a more specific but still potentially polymorphic type. PM in this system narrows to concrete property types, but each order of FA gives a polymorphic function.)\n\n\nt2 = Tree(\"S\", [\"NP\", \"VP\"])\nr2 = lang.compose(t2)\nr2.tree()\nr2.paths()\n\n3 composition paths:\nPath [0]:\n$[\\![\\text{\\textbf{NP}}]\\!]^{}_{\\forall{}X}$*$[\\![\\text{\\textbf{VP}}]\\!]^{}_{\\forall{}X}$[FA/left]$[\\![\\text{\\textbf{S}}]\\!]^{}_{X'}$$[\\![\\text{\\textbf{NP}}]\\!]^{}_{\\left\\langle{}X,X'\\right\\rangle{}}([\\![\\text{\\textbf{VP}}]\\!]^{}_{X})$Path [1]:\n$[\\![\\text{\\textbf{NP}}]\\!]^{}_{\\forall{}X}$*$[\\![\\text{\\textbf{VP}}]\\!]^{}_{\\forall{}X}$[FA/right]$[\\![\\text{\\textbf{S}}]\\!]^{}_{X'}$$[\\![\\text{\\textbf{VP}}]\\!]^{}_{\\left\\langle{}X,X'\\right\\rangle{}}([\\![\\text{\\textbf{NP}}]\\!]^{}_{X})$Path [2]:\n$[\\![\\text{\\textbf{NP}}]\\!]^{}_{\\forall{}X}$*$[\\![\\text{\\textbf{VP}}]\\!]^{}_{\\forall{}X}$[PM]$[\\![\\text{\\textbf{S}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: [\\![\\text{\\textbf{NP}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}({x}) \\wedge{} [\\![\\text{\\textbf{VP}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}({x})$\n\n\nWe can supply lexical entries to form a complete tree fragment. Composition can still happen in any order, e.g. by default it works top down. If we compose one step the leaf node “gray” is not yet looked up; but composing the whole thing is possible.\n\nTree = lamb.utils.get_tree_class()\nt = Tree(\"NP\", [\"gray\", Tree(\"N\", [\"cat\"])])\nt\n\n\n\n\n\n\n\n\n\nt2 = lang.CompositionTree.tree_factory(t)\nr = lang.compose(t2)\nr\n\n3 composition paths. Results:     [0]: \\([\\![\\text{\\textbf{NP}}]\\!]^{}_{X'} \\:=\\: [\\![\\text{\\textbf{gray}}]\\!]^{}_{\\left\\langle{}X,X'\\right\\rangle{}}([\\![\\text{\\textbf{N}}]\\!]^{}_{X})\\)     [1]: \\([\\![\\text{\\textbf{NP}}]\\!]^{}_{X'} \\:=\\: [\\![\\text{\\textbf{N}}]\\!]^{}_{\\left\\langle{}X,X'\\right\\rangle{}}([\\![\\text{\\textbf{gray}}]\\!]^{}_{X})\\)     [2]: \\([\\![\\text{\\textbf{NP}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: [\\![\\text{\\textbf{N}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}({x}) \\wedge{} [\\![\\text{\\textbf{gray}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}({x})\\)\n\n\n\nr.tree()\n\n$[\\![\\text{\\textbf{gray}}]\\!]^{}_{\\forall{}X}$*$[\\![\\text{\\textbf{N}}]\\!]^{}_{\\forall{}X}$$[\\![\\text{\\textbf{NP}}]\\!]$[path 0]: $[\\![\\text{\\textbf{NP}}]\\!]^{}_{X'} \\:=\\: [\\![\\text{\\textbf{gray}}]\\!]^{}_{\\left\\langle{}X,X'\\right\\rangle{}}([\\![\\text{\\textbf{N}}]\\!]^{}_{X})$[path 1]: $[\\![\\text{\\textbf{NP}}]\\!]^{}_{X'} \\:=\\: [\\![\\text{\\textbf{N}}]\\!]^{}_{\\left\\langle{}X,X'\\right\\rangle{}}([\\![\\text{\\textbf{gray}}]\\!]^{}_{X})$[path 2]: $[\\![\\text{\\textbf{NP}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: [\\![\\text{\\textbf{N}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}({x}) \\wedge{} [\\![\\text{\\textbf{gray}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}({x})$\n\n\n\nr2 = lang.get_system().expand_all(t2)\nr2\n\n1 composition path. Result:     [0]: \\([\\![\\text{\\textbf{NP}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Gray}({x})\\)\n\n\n\nr2.tree()\n\n$[\\![\\text{\\textbf{gray}}]\\!]$[path 0]: $[\\![\\text{\\textbf{gray}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {Gray}({x})$*$[\\![\\text{\\textbf{cat}}]\\!]$[path 0]: $[\\![\\text{\\textbf{cat}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {Cat}({x})$$[\\![\\text{\\textbf{N}}]\\!]$[path 0]: $[\\![\\text{\\textbf{N}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {Cat}({x})$$[\\![\\text{\\textbf{NP}}]\\!]$[path 0]: $[\\![\\text{\\textbf{NP}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}} \\:=\\: \\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Gray}({x})$\n\n\n\nr2.paths()\n\n1 composition path:$[\\![\\text{\\textbf{gray}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$[Lexicon]$\\lambda{} x_{e} \\: . \\: {Gray}({x})$*$[\\![\\text{\\textbf{cat}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$[Lexicon]$\\lambda{} x_{e} \\: . \\: {Cat}({x})$[NN]$[\\![\\text{\\textbf{N}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x})$[PM]$[\\![\\text{\\textbf{NP}}]\\!]^{}_{\\left\\langle{}e,t\\right\\rangle{}}$$\\lambda{} x_{e} \\: . \\: {Cat}({x}) \\wedge{} {Gray}({x})$"
  },
  {
    "objectID": "demo-for-linguists.html#part-3-human-readable-rendering-of-structured-python-objects",
    "href": "demo-for-linguists.html#part-3-human-readable-rendering-of-structured-python-objects",
    "title": "Lambda notebook demo",
    "section": "3.3 Part 3: human readable rendering of structured python objects",
    "text": "3.3 Part 3: human readable rendering of structured python objects\nAt this point in the demo, the output of the lambda notebook needs no introduction: it has been used at every stage of the document. The lambda notebook is designed from the ground up so that nearly every python class supports IPython/Jupyter’s rich outputs, rendering in human-readable form to a combination of LaTeX and HTML that can be displayed in Jupyter Notebooks (Kluyver et al. 2016) and on the web.\n\nKluyver, Thomas, Benjamin Ragan-Kelley, Fernando Pérez, Brian Granger, Matthias Bussonnier, Jonathan Frederic, Kyle Kelley, et al. 2016. “Jupyter Notebooks – a Publishing Format for Reproducible Computational Workflows.” Edited by F. Loizides and B. Schmidt. IOS Press.\n\nLaTeX math mode output in Jupyter is rendered via MathJax (and on google colab, via KaTeX).\n\nFor example, here is an example lambda expression from earlier:\n\npmw_test1 = %te L p_t : L x_e : P_&lt;e,t&gt;(x) & p\npmw_test1\n\n\\(\\lambda{} p_{t} \\: . \\: \\lambda{} x_{e} \\: . \\: {P}({x}) \\wedge{} {p}\\)\n\n\nThis object can be recursively converted into a LaTeX math mode expression, and this automatically happens when displaying such objects in Jupyter.\n\nprint(pmw_test1._repr_latex_())\n\n$\\lambda{} p_{t} \\: . \\: \\lambda{} x_{e} \\: . \\: {P}({x}) \\wedge{} {p}$\n\n\nMore complex outputs, like composition trees, mix LaTeX and HTML output."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About the Lambda Notebook project",
    "section": "",
    "text": "The Jupyter Lambda Notebook is a project that aims to implement compositional semantics and supporting formal theories from linguistics in Python, integrated tightly with Jupyter. One main goal is to provide a useful interface for linguists who want to implement their semantic analyses – allowing the construction of interactive ‘digital fragments’ (following the classic method of fragments from Montague grammar).\n\nAuthor: Kyle Rawlins, kgr@jhu.edu\nDependencies: python 3, svgling, (optional) Jupyter\nRepository and issue tracker: https://github.com/rawlins/lambda-notebook/\nInstallation: download from github, or pip install lambda-notebook to install the current release version from PyPI.\nLicense: MIT License"
  },
  {
    "objectID": "about.html#about-the-package",
    "href": "about.html#about-the-package",
    "title": "About the Lambda Notebook project",
    "section": "",
    "text": "The Jupyter Lambda Notebook is a project that aims to implement compositional semantics and supporting formal theories from linguistics in Python, integrated tightly with Jupyter. One main goal is to provide a useful interface for linguists who want to implement their semantic analyses – allowing the construction of interactive ‘digital fragments’ (following the classic method of fragments from Montague grammar).\n\nAuthor: Kyle Rawlins, kgr@jhu.edu\nDependencies: python 3, svgling, (optional) Jupyter\nRepository and issue tracker: https://github.com/rawlins/lambda-notebook/\nInstallation: download from github, or pip install lambda-notebook to install the current release version from PyPI.\nLicense: MIT License"
  },
  {
    "objectID": "about.html#about-the-author",
    "href": "about.html#about-the-author",
    "title": "About the Lambda Notebook project",
    "section": "About the author",
    "text": "About the author\nThe lambda notebook package is developed by Kyle Rawlins. I’m a faculty member in the Cognitive Science department at JHU; my research areas are in theoretical and computational linguistics, focusing on semantics and pragmatics."
  },
  {
    "objectID": "about.html#about-the-website",
    "href": "about.html#about-the-website",
    "title": "About the Lambda Notebook project",
    "section": "About the website",
    "text": "About the website\nThis website is rendered from runnable Jupyter notebooks using quarto. The source notebooks and page generation code can be found at: https://github.com/rawlins/lambda-notebook/tree/master/docs."
  }
]