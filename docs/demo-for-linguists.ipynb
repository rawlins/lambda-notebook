{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Lambda notebook demo\"\n",
    "date: 2024-08-26\n",
    "author:\n",
    "  - name: Kyle Rawlins\n",
    "    email: kgr@jhu.edu\n",
    "toc: true\n",
    "toc-expand: 2\n",
    "number-sections: true\n",
    "bibliography: lambda.bib\n",
    "citation-location: margin\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.content-hidden}\n",
    "\n",
    "Note! This document in is partly in `quarto`-flavored markdown and can be used with the `quarto` package to generate a rendered version overview. For this reason you will see occasional raw cells and things like the first line of this cell that will render oddly as a plain jupyter notebook.\n",
    "\n",
    "# Lambda notebook demo (for linguists)\n",
    "\n",
    "Author: **Kyle Rawlins, [kgr@jhu.edu](kgr@jhu.edu)**\n",
    "\n",
    "**Current version**: v2.0, 2024-08-26\n",
    "\n",
    "This notebook provides a demo of the core capabilities of the lambda notebook, aimed at linguists who already have training in semantics (but not necessarily implemented semantics).\n",
    "\n",
    "Last updated Aug 2024. Version history:\n",
    "\n",
    " * 0.5: first version\n",
    " * 0.6: updated to work with refactored class hierarchy (Apr 2013)\n",
    " * 0.6.1: small fixes to adapt to changes in various places (Sep 2013)\n",
    " * 0.7: various fixes to work with alpha release (Jan 2014)\n",
    " * 0.9: substantial updates, merge content from LSA poster (Apr 2014)\n",
    " * 0.95: substantial updates for a series of demos in Apr-May 2014\n",
    " * 1.0: various changes / fixes, more stand-alone text (2017)\n",
    " * 1.0.1: small tweaks (Nov/Dec 2018)\n",
    " * 1.0.2: bugfixes\n",
    " * 1.1: updates towards quarto refactoring\n",
    " * 2.0: quarto refactor\n",
    " \n",
    "If you are viewing this demo interactively, you can run through code cells via shift-enter, or by the run button in the toolbar.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import lamb.auto\n",
    "from lamb.types import TypeMismatch, type_e, type_t, type_property\n",
    "from lamb.meta import TypedTerm, TypedExpr, LFun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "# Interactive note: there are several ways of display outputs, this one is the default:\n",
    "lamb.display.default(style=lamb.display.DerivStyle.BOXES)\n",
    "# you can also try:\n",
    "# lamb.display.default(style=lamb.display.DerivStyle.PROOF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Download this notebook](https://github.com/rawlins/lambda-notebook/blob/master/docs/demo-for-linguists.ipynb) for interactive use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First pitch to a theoretical linguist\n",
    "\n",
    "Have you ever wanted to type something like this in, and have it actually do something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%lamb\n",
    "||every|| = λ f_<e,t> : λ g_<e,t> : Forall x_e : f(x) >> g(x)\n",
    "||cat|| = L x_e : Cat_<e,t>(x)\n",
    "||meowed|| = L x_e : Meowed_<e,t>(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = ((every * cat) * meowed)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lambda notebook project aims to make this happen. It provides:\n",
    "\n",
    "1. flexible typed metalanguage: a superset of first-order predicate logic, together with a rich type theory.\n",
    "2. a framework for doing semantic composition on natural language syntax\n",
    "3. an api for rendering the structured python objects in layers 1-2 in easy-to-read MathJax (web-oriented LaTeX code) and HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background: Two problems in formal semantics\n",
    "\n",
    "1. Type-driven computation could be a lot easier to visualize and check.\n",
    "\n",
    "2. Grammar fragments as in Montague Grammar: good idea in principle, hard to use in practice.\n",
    "\n",
    "  * A **fragment** is a *complete* formalization of *sublanguage* consisting of the *key relevant phenomena* for the problem at hand.  (Potential problem-points italicized.)\n",
    "\n",
    "Solution: a system for developing interactive fragments: the \"*Lambda Notebook*\" project.\n",
    "\n",
    "* Creator can work interactively with analysis -- accelerate development, limit time spent on tedious details.\n",
    "* Reader can explore derivations in ways that are not typically possible in typical paper format.\n",
    "* Creator and reader can be certain that derivations work, verified by the system.\n",
    "* Bring closer together formal semantics and computational modeling.\n",
    "\n",
    "Inspirations and related projects:\n",
    "\n",
    " * @vanEijckUnger10: implementation of compositional semantics in Haskell.  No interface (beyond standard Haskell terminal); great if you like Haskell. There's a rich tradition of programmer linguists writing fragments in Haskell following this book.\n",
    " * The [Lambda calculator](http://lambdacalculator.com/) [originally, the UPenn Lambda Calculator, @PennLambda]: teaching oriented implementation of lambda calculus in Java.\n",
    " * [`nltk.sem`](https://www.nltk.org/api/nltk.sem.html): implementation of the lambda calculus with a typed metalanguage, interface with theorem provers.  No interactive interface.\n",
    "\n",
    "## The role of formalism & fragments in semantics\n",
    "\n",
    "What does *formal* mean in semantics?  What properties should a theory have?\n",
    "\n",
    " 1. Mathematically precise (lambda calculus, type theory, logic, model theory(?), ...)\n",
    " 2. Complete (covers \"all\" the relevant data).\n",
    " 3. Predictive (like any scientific theory).\n",
    " 4. Consistent, or at least compatible (with itself, analyses of other phenomena, some unifying conception of the grammar).\n",
    " \n",
    "The *method of fragments* [@Partee79; @ParteeHendriks97] provides a structure for meeting these criteria.\n",
    "\n",
    " * Paper with a fragment provides a working system.  (Probably.)\n",
    " * Explicit outer bound for empirical coverage.\n",
    " * Integration with a particular theory of grammar.  (To some extent.)\n",
    " * Explicit answer to many detailed questions not necessarily dealt with in the text.\n",
    " \n",
    "**Claim**: fragments are a method of replicability, similar to a computational modeller providing their model.\n",
    "\n",
    " * To be clear, a fragment is neither necessary nor sufficient for having a good theory / analysis / paper...\n",
    "\n",
    "Additional benefit: useful internal check for researcher.\n",
    "\n",
    "> \"...But I feel strongly that it is important to try to [work with fully explicit fragments] periodically, because otherwise it is extremely easy to think that you have a solution to a problem when in fact you don't.\" (Partee 1979, p. 41)\n",
    "\n",
    "## The challenges of fragments\n",
    "\n",
    "Part 1 of the above quote:\n",
    "\n",
    ">\"It can be very frustrating to try to specify frameworks and fragments explicitly; this project has not been entirely rewarding.  I would not recommend that one always work with the constraint of full explicitness.\" (Ibid.)\n",
    "\n",
    " * Fragments can be tedious and time-consuming to write (not to mention hard).\n",
    " * Fragments as traditionally written are in practice not easy for a reader to use.\n",
    " \n",
    "   - Dense/unapproachable.  With exactness can come a huge chunk of hard-to-digest formalism.  E.g. @Partee79, the fragment is about 10% of the paper.\n",
    "   - Monolithic/non-modular.  For the specified sublanguage, everything is specified.  Outside the bounds of the sublanguage, nothing is specified.  How does the theory fit in with others?\n",
    "   - Exact opposite of the modern method -- researchers typically hold most aspects of the grammar constant (implicitly) while changing a few key points.  [See e.g., the introduction to @PortnerPartee02 for discussion.]\n",
    "\n",
    "**Summary:** In practice, the typical payoff for neither the reader nor the writer of a fragment exceeded the effort.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A solution: digital fragments\n",
    "\n",
    "@vanEijckUnger10's solution: we can (and perhaps should) specify a fragment in digital form.\n",
    "\n",
    "* They use Haskell.  Type system of Haskell extremely well-suited to natural language semantics.\n",
    "* (Provocative statement) Interface, learning curve of Haskell not well suited to semanticists (or most people)? At a minimum: reading code is not always easy.\n",
    "\n",
    "**Benefits of digital fragments (in principle)**\n",
    "\n",
    "* Interactive.\n",
    "* Easy to distribute, adapt, modify.\n",
    "* Possibility of modularity.  (E.g. abstract a 'library' for compositional systems away from the analysis of a particular phenomenon.)\n",
    "* Bring closer together the CogSci idea of a 'computational model' to the project of natural language semantics.\n",
    "\n",
    "**What sorts of things might we want in a fragment / system for fragments?**\n",
    "\n",
    "* Typed lambda calculus.\n",
    "* Logic / logical metalanguage.\n",
    "* Model theory.\n",
    "* Framework for semantic composition.\n",
    "\n",
    "The Lambda Notebook project aims to provide these tools in a usable, interactive, format, built on type of Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: flexible typed metalanguage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **metalanguage** infrastructure is a set of python classes that implement the building blocks of logical expressions, lambda terms, and various other formal objects, as well as complex formulas built from these pieces. This rests on an implementation of a framework for **type systems** that matches what semanticists tend to assume.\n",
    "\n",
    "Preface cell with `%%lamb` to enter metalanguage formulas directly.  The following cell defines a variable `x` that has type e, and exports it to the notebook's environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%lamb reset\n",
    "x = x_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell defines some variables whose values are more complex object -- in fact, functions in the typed lambda calculus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%lamb\n",
    "test1 = L p_t : L x_e : P_<e,t>(x) & p # based on a Partee et al example\n",
    "test1b = L x_e : P_<e,t>(x) & Q_<e,t>(x)\n",
    "t2 = Q_<e,t>(x_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are now registered as variables in the python namespace and can be manipulated directly.  A typed lambda calculus is fully implemented with all that that entails -- e.g. the value of `test1` includes the whole syntactic structure of the formula, its type, etc. and can be used in constructing new formulas.  The following cells build a complex function-argument formula, and following that, does the reduction.\n",
    "\n",
    "Notice that beta reduction works properly, i.e. bound $x$ in the function is renamed in order to avoid collision with the free `x` in the argument. [`test1b` is based on an example illustrating alpha conversion from @PMW93.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1(t2) # construct a complex function-argument expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1(t2).reduce() # do reduction on that expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%lamb\n",
    "catf = L x_e: Cat_<e,t>(x)\n",
    "dogf = λx: Dog_<e,t>(x_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(catf(x), (catf(x)).type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catf.type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type checking of course is a part of all this.  If the types don't match, the computation will throw a `TypeMismatch` exception.  The following cell uses python syntax to catch and print such errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with lamb.errors():\n",
    "    test1(x) # function is type <t,<e,t>> so will trigger a type mismatch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more complex expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%lamb\n",
    "p2 = (Cat_<e,t>(x_e) & p_t) >> (Exists y: Dog_<e,t>(y_e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is going on behind the scenes?  The objects manipulated are recursively structured python objects (of class `TypedExpr`). Each layer of recursion stores information about the kind of metalanguage expression it is, as well as its parts.\n",
    "\n",
    "Many straightforward expressions can be parsed.  Most expressions are created using a call to TypedExpr.factory, which is abbreviated as \"te\" in the following examples.  The `%%lamb` magic is calling this behind the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = %te x_e\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various convenience python operators are overloaded, including functional calls.  Here is an example repeated from earlier in two forms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%lamb\n",
    "p2 = (Cat_<e,t>(x_e) & p_t) >> (Exists y: Dog_<e,t>(y_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = (te(\"Cat_<e,t>(x)\") & te(\"p_t\")) >> te(\"(Exists y: Dog_<e,t>(y_e))\")\n",
    "p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine in detail what happens when a function and argument combine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catf = meta.LFun(te(\"x_e\"), te(\"Cat(x_e)\"))\n",
    "catf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catf(te(\"y_e\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a function-argument expression builds a complex, unreduced expression.  This can be explicitly reduced (note that the `reduce_all()` function would be used to apply reduction  recursively):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catf(te(\"y_e\")).reduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(catf(te(\"y_e\")).reduce()).derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metalanguage supports type polymorphism. For example, we can define a function whose input type is a type variable (`X`) and then combine that function with a concrete type, to force type narrowing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lamb ttest = L x_X : P_<X,t>(x)\n",
    "%lamb tvar = y_t\n",
    "ttest(tvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other operators not illustrated here include set theoretic expressions, tools for building partial functions and denotations, a rich approach to \"meta-meta-language\", restricted quantifiers, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model theory and evaluation\n",
    "\n",
    "The lambda notebook supports model theory and evaluation of extensional formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = meta.Model({'A': '_c1',\n",
    "                'B': '_c2',\n",
    "                'C': '_c1',\n",
    "                'P': {'A', 'B'}},\n",
    "               domain={'_c1', '_c2', '_c3'})\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.evaluate(te(\"Exists x_e : P_<e,t>(x)\")).derivation.trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.evaluate(te(\"Forall x_e : P_<e,t>(x)\")).derivation.trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: composition systems for an object language\n",
    "\n",
    "On top of the metalanguage are '**composition systems**' for modeling (step-by-step) semantic composition in an object language such as English.  This is the part of the lambda notebook that tracks and manipulates mappings between object language elements (words, trees, etc) and denotations in the metalanguage.  \n",
    "\n",
    "A composition system at its core consists of a set of composition rules; the following cell defines a simple composition system that will be familiar to anyone who has taken a basic course in compositional semantics. [See among others, @HeimKratzer98; @IFS24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# none of this is strictly necessary, the built-in library already provides effectively this system.\n",
    "fa = lang.BinaryCompositionOp(\"FA\", lang.fa_fun, reduce=True)\n",
    "pm = lang.BinaryCompositionOp(\"PM\", lang.pm_fun, commutative=True, reduce=True)\n",
    "pa = lang.BinaryCompositionOp(\"PA\", lang.pa_fun, allow_none=True)\n",
    "demo_hk_system = lang.CompositionSystem(name=\"demo system\", rules=[fa, pm, pa])\n",
    "lang.set_system(demo_hk_system)\n",
    "demo_hk_system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expressing denotations is done in a `%%lamb` cell, and almost always begins with lexical items.  The following cell defines several lexical items that will be familiar from introductory exercises in the @HeimKratzer98 textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%lamb\n",
    "||cat|| = L x_e: Cat_<e,t>(x)\n",
    "||gray|| = L x_e: Gray_<e,t>(x)\n",
    "||john|| = John_e\n",
    "||julius|| = Julius_e\n",
    "||inP|| = L x_e : L y_e : In_<(e,e),t>(y, x) # `in` is a reserved word in python\n",
    "||texas|| = Texas_e\n",
    "||isV|| = L p_<e,t> : p # `is` is a reserved word in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All object-language representations implement the interface `lamb.lang.Composable`, including lexical items as well as the complex results shown below. In type-driven mode, composition is triggered by using the '`*`' operator on a `Composable`.  This searches over the available composition operations in the system to see if any results can be had.  Given their types, we expect `inP` and `texas` above to be able to compose using the FA rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inP * texas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand `isV` is looking for a property, so we shouldn't expect succesful composition with a type `e` element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "julius * isV # will fail due to type mismatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Composition results are `Composable`s as well, and so can be further composed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = julius * (isV * (inP * texas))\n",
    "display(sentence1[0].source_tree())\n",
    "sentence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1.trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Composition will find all possible paths, but in the current example there are no ambiguities. (Note: the metalanguage by default normalizes the order of conjuncts alphabetically, so the order in the output of PM is independent of what composes with what. This is why the operation is marked \"commutative\" when defined earlier -- so the composition system knows it doesn't need to bother with both orders.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray * cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray * (cat * (inP * texas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = lang.Item(\"a\", isV.content) # identity function for copula as well\n",
    "isV * (a * (gray * cat * (inP * texas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np = ((gray * cat) * (inP * texas))\n",
    "vp = (isV * (a * np))\n",
    "sentence2 = julius * vp\n",
    "sentence2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1.results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| column: screen-inset-right\n",
    "sentence1.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| column: screen-inset-right\n",
    "sentence2.tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a well-known example exercise from @HeimKratzer98 (names different):\n",
    "\n",
    "    (1) Julius is a gray cat in Texas fond of John.\n",
    " \n",
    "Calculating the denotation of this is relatively straightforward, as long as the lexical items and order of composition are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fond = lang.Item(\"fond\", \"L x_e : L y_e : Fond(y)(x)\")\n",
    "ofP = lang.Item(\"of\", \"L x_e : x\")\n",
    "sentence3 = julius * (isV * (a * (((gray * cat) * (inP * texas)) * (fond * (ofP * john)))))\n",
    "display(sentence3[0].source_tree())\n",
    "sentence3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| column: screen-inset-right\n",
    "sentence3.tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Composite` class supports indexing, so we can pull out subparts of a derivaiton:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| column: screen-inset-right\n",
    "parse_tree3 = sentence3.results[0]\n",
    "parse_tree3[1][1][1].tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is support for traces and indexed pronouns, using a version of the Predicate Abstraction (PA) rule [based on the version in @IFS24]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binder = lang.Binder(23)\n",
    "binder2 = lang.Binder(5)\n",
    "t = lang.Trace(23, types.type_e)\n",
    "t2 = lang.Trace(5)\n",
    "display(t, t2, binder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((t * gray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = (binder * (binder2 * (t * (inP * t2))))\n",
    "b2 = (binder2 * (binder * (t * (inP * t2))))\n",
    "display(b1, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1.trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| column: screen-inset-right\n",
    "b1.results[0].tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composition in tree structures\n",
    "\n",
    "In many contexts it is natural to just use bottom-up composition, especially given the implementation of the PA rule. However, the lambda notebook supports arbtirarily-sequenced composition in tree structures, with deferred composition when missing bottom-up information. This uses `Tree` objects with an interface designed after those in the [nltk package](https://www.nltk.org/). In these derivations, you can see some of the support for inference over variable types. This composition system more directly matches the classic one presented in @HeimKratzer98."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.content-hidden}\n",
    "\n",
    "**note** when working with this interactively: running the following cell well change the behavior of many of the prior cells, unless the composition system is reset!\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang.set_system(lang.hk_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%lamb\n",
    "||gray|| = L x_e : Gray_<e,t>(x)\n",
    "||cat|| = L x_e : Cat_<e,t>(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = Tree(\"S\", [\"NP\", \"VP\"])\n",
    "t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We *can* do composition in this tree fragment, but the leaf nodes (not being in the lexicon) are treated as placeholders. They are accordingly assigned polymorphic types.\n",
    "\n",
    "* (The type $\\forall X$ is a type that can be anything at all; this gets narrowed by each possible composition rule that could apply to a more specific but still potentially polymorphic type. PM in this system narrows to concrete property types, but each order of FA gives a polymorphic function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = Tree(\"S\", [\"NP\", \"VP\"])\n",
    "r2 = lang.compose(t2)\n",
    "r2.tree()\n",
    "r2.paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can supply lexical entries to form a complete tree fragment. Composition can still happen in any order, e.g. by default it works top down. If we compose one step the leaf node \"gray\" is not yet looked up; but composing the whole thing is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree = lamb.utils.get_tree_class()\n",
    "t = Tree(\"NP\", [\"gray\", Tree(\"N\", [\"cat\"])])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = lang.CompositionTree.tree_factory(t)\n",
    "r = lang.compose(t2)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = lang.get_system().expand_all(t2)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2.paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: human readable rendering of structured python objects\n",
    "\n",
    "At this point in the demo, the output of the lambda notebook needs no introduction: it has been used at every stage of the document. The lambda notebook is designed from the ground up so that nearly every python class supports IPython/Jupyter's rich outputs, rendering in human-readable form to a combination of LaTeX and HTML that can be displayed in Jupyter Notebooks [@Kluyver:2016aa] and on the web. \n",
    "\n",
    "* LaTeX math mode output in Jupyter is rendered via [MathJax](https://www.mathjax.org/) (and on google colab, via [KaTeX](https://katex.org/)).\n",
    "\n",
    "For example, here is an example lambda expression from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmw_test1 = %te L p_t : L x_e : P_<e,t>(x) & p\n",
    "pmw_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object can be recursively converted into a LaTeX math mode expression, and this automatically happens when displaying such objects in Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pmw_test1._repr_latex_())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complex outputs, like composition trees, mix LaTeX and HTML output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "The lambda notebook provides:\n",
    "\n",
    "* a flexible api/framework for implementing a logical typed metalanguage\n",
    "* a framework for implementing compositional systems based on linguistic semantics\n",
    "* an api for displaying structured objects in a linguist-readable way\n",
    "\n",
    "It does this in the context of Jupyter notebook, which further provides facilities for interleaving code (of various kinds) and documentation.\n",
    "\n",
    "**More info**: please see the many [example and documentation notebooks](https://github.com/rawlins/lambda-notebook/tree/master/notebooks) provided with the project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
